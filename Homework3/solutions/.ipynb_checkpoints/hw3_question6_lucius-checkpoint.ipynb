{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "#from gensim import downloader\n",
    "import matplotlib.pyplot as plt\n",
    "#from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drama</td>\n",
       "      <td>A Bill of Divorcement describes a day in the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Dr. Clitterhouse (Edward G. Robinson) is a wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Three young couples, all having financial stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Hollywood studio mogul Joe Mulholland (Matthau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>drama</td>\n",
       "      <td>In a working class South London district lives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10711</th>\n",
       "      <td>10711</td>\n",
       "      <td>comedy</td>\n",
       "      <td>In a North of England training camp, lovestruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>10712</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Avijit Banerjee runs his own software company....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10713</th>\n",
       "      <td>10713</td>\n",
       "      <td>drama</td>\n",
       "      <td>Elangovan (Thankar Bachchan) is a school teach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10714</th>\n",
       "      <td>10714</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Victor Maynard (Bill Nighy) is an experienced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10715</th>\n",
       "      <td>10715</td>\n",
       "      <td>drama</td>\n",
       "      <td>Popular rock singer and aspiring revolutionary...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10716 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Genre                                               Plot\n",
       "0               0   drama  A Bill of Divorcement describes a day in the l...\n",
       "1               1  comedy  Dr. Clitterhouse (Edward G. Robinson) is a wea...\n",
       "2               2  comedy  Three young couples, all having financial stru...\n",
       "3               3  comedy  Hollywood studio mogul Joe Mulholland (Matthau...\n",
       "4               4   drama  In a working class South London district lives...\n",
       "...           ...     ...                                                ...\n",
       "10711       10711  comedy  In a North of England training camp, lovestruc...\n",
       "10712       10712  comedy  Avijit Banerjee runs his own software company....\n",
       "10713       10713   drama  Elangovan (Thankar Bachchan) is a school teach...\n",
       "10714       10714  comedy  Victor Maynard (Bill Nighy) is an experienced ...\n",
       "10715       10715   drama  Popular rock singer and aspiring revolutionary...\n",
       "\n",
       "[10716 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie-plots-student.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For preprocessing, we will tokenize, lemmatize, and remove any stopwords and non-alphanumeric characters from each document. Next we'll load our word embedding model to embed each movie plot as a vector. We'll use the pre-trained w2v model trained on the Google news vectors and embed each word in each document as a 300 dimensional vector, and use a simple average vector for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading embedding model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'downloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d877cad8e0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_vectors.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded X_vectors.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_vectors.npy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d877cad8e0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading embedding model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preprocessing text...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'downloader' is not defined"
     ]
    }
   ],
   "source": [
    "# load vectors for training or create them\n",
    "try:\n",
    "    X_vectors = np.load('X_vectors.npy')\n",
    "    print('Loaded X_vectors.')\n",
    "except:\n",
    "    # load/download embedding model\n",
    "    model_name = 'word2vec-google-news-300'\n",
    "    file = Path(f'{os.path.expanduser(\"~\")}/gensim-data/{model_name}/{model_name}.gz')\n",
    "    if file.is_file():\n",
    "        print('Loading embedding model...')\n",
    "        embedding_model = KeyedVectors.load_word2vec_format(str(file), binary=True)\n",
    "    else:\n",
    "        print('Downloading embedding model...')\n",
    "        embedding_model = downloader.load(model_name)\n",
    "    \n",
    "    print('Preprocessing text...')\n",
    "    # load english module\n",
    "    nlp = spacy.load('en')\n",
    "\n",
    "    # embed each document as average word vector\n",
    "    # impute with zero vectors\n",
    "    embedding_dim = 300\n",
    "    documents = df.Plot\n",
    "    vector = np.zeros((embedding_dim, ))\n",
    "    vectors = np.empty((len(documents), embedding_dim))\n",
    "    for i, doc in enumerate(tqdm(documents)):\n",
    "        # tokenize, lemmatize, stopwords, non-alphanumeric characters\n",
    "        clean_doc = [token.lemma_ for token in nlp(doc) \n",
    "                     if not token.is_stop and token.is_alpha]\n",
    "        vector *= 0\n",
    "        num_words = 0\n",
    "        for word in clean_doc:\n",
    "            if word in embedding_model.vocab:\n",
    "                vector += embedding_model[word]\n",
    "                num_words += 1\n",
    "        if num_words > 0:\n",
    "            vector /= num_words\n",
    "\n",
    "        vectors[i] = vector\n",
    "\n",
    "    np.save('X_vectors.npy', vectors)\n",
    "    X_vectors = vectors\n",
    "    print('X_vectors created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create integer labels from our categories and check for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels as integers\n",
    "y_labels = df.Genre.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_labels);\n",
    "plt.title('Training class balance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a multiclass logistic regression using multinomial loss across all classes. We'll use an elasticnet tuned with 5-fold cross validation to find the optimal C (regularization strength) and l1_ration (ratio between L1 and L2 penalty). We use sample weights inversely proportional to the class frequencies to account for class imbalance. For timing purposes, we'll keep the number of iterations low enough the fitting isn't too slow. We perform an initial train/test split just to get an idea of our performance before doing our cross validation process on all of the training data to get our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# standardize features to enable regularization\n",
    "X_vectors = StandardScaler().fit_transform(X_vectors)\n",
    "\n",
    "# make train test split to get idea of test performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y_labels, stratify=y_labels,\n",
    "                                                    random_state=123, test_size=0.25)\n",
    "\n",
    "# use multiclass logistic regression with multinomial loss across all classes \n",
    "# elasticnet with 5-fold cross validation to find optimal C (regularization strength) \n",
    "# and l1_ratio (ratio between L1 and L2 penalty)\n",
    "# best model chosen based on f1-score\n",
    "# use sample weights inversely proportional to the class frequencies to handle imbalance\n",
    "# we'll keep max_iter low enough that fitting isn't too slow\n",
    "parameters = {'Cs': [1e-4, 1e-2, 1, 1e2, 1e4], 'l1_ratios': [0, 0.5, 1]}\n",
    "model = LogisticRegressionCV(random_state=123, multi_class='multinomial',\n",
    "                             penalty='elasticnet', solver='saga', max_iter=200,\n",
    "                             class_weight='balanced', verbose=1, n_jobs=-1,\n",
    "                             **parameters)\n",
    "\n",
    "# ignore max_iter warning since we're printing out convergence\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sense of test accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now use the same process to train on all of the data with more iterations\n",
    "model.fit(X_vectors, y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our best model trained, we're ready to predict on the held out test data. We write a function to do the same preprocessing and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data):\n",
    "    # NOTE: this function assumes except case was triggered above\n",
    "    # and variables used are thus available\n",
    "    vector = np.zeros((embedding_dim, ))\n",
    "    X_test = np.empty((len(test_data), embedding_dim))\n",
    "    for i, doc in enumerate(tqdm(test_data)):\n",
    "        # tokenize, lemmatize, stopwords, non-alphanumeric characters\n",
    "        clean_doc = [token.lemma_ for token in nlp(doc) \n",
    "                     if not token.is_stop and token.is_alpha]\n",
    "        vector *= 0\n",
    "        num_words = 0\n",
    "        for word in clean_doc:\n",
    "            if word in embedding_model.vocab:\n",
    "                vector += embedding_model[word]\n",
    "                num_words += 1\n",
    "        if num_words > 0:\n",
    "            vector /= num_words\n",
    "\n",
    "        X_test[i] = vector\n",
    "    \n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
