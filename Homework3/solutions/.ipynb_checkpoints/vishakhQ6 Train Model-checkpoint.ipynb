{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "To start the training process, I divide the reviews randomly in 4:1 ratio for a train-validation split to evaluate the training process.\n",
    "\n",
    "Then the train movie reviews have pretty high standard deviation in length so we select those reviews that fall within two standard deviations of the mean in terms of length so as to remove some outliers. This doesn't discard many in any case. \n",
    "\n",
    "The next step is to convert the labels from categorical strings i.e. horror, comedy etc. to integer values. This is done with a simple dictionary but it's important that we retain this map even at inference time so I persistently store the same. \n",
    "\n",
    "Looking at the plots, a vast number of words within them are names of people/places and these add a lot of different words to the vocabulary but don't necessarily convey much additional information. In lieu of this, I use nltk to identify proper nouns within them i.e. POS tag == NNP or NNPS, and then replace all of these with a single NNP token. (I validated with and without this modification and noticed an improvement). This could potentially lose some information but the goal is to build a robust classifier so perhaps it is not so best to learn from such proper nouns because they can lead to some spurious correlations in classification. \n",
    "\n",
    "The next step is to tokenize and filter out stopwords as we had done in the lab. Again NLTK helps here. I also filter out the NNP token here because it is clearly the most common token. \n",
    "\n",
    "I experimented with porter stemming/lemmatization but it didn't obtain an improvement and since we only have ~10^5 examples we can train without this step. \n",
    "\n",
    "Once we have this, we can move on to vectorization. As we had done in the lab I try out three approaches: binary, bag of words and tfidf. For this I used a sparse matrix setup similar to the lab. \n",
    "\n",
    "For classification from these features, I try out multiple models from logistic regression, SVM, Random forest and the Gaussian Naive Bayes and the Gaussian NB was the one that obtained the highest validation accuracy/F1 score so I chose to proceed with this. For each I experimented with a few variations in parameters using the validation set and ultimately went with GNB.\n",
    "\n",
    "Interestingly, the bag of words representation obtained the best performance while tfidf was unable to classify the two minority classes well and the binary approach could not match the bow in performance. \n",
    "\n",
    "We persistently store both the models as well as vectorizers needed to perform classification so that it can be used in inference.\n",
    "\n",
    "### Inference\n",
    "\n",
    "At inference time, we accept a list of strings and labels. First we load the dictionary map for labels from the persistent storage and encode the labels appropriately. Then first we tokenize and remove stopwords/NNP tokens as we had in the train phase. Then we load the persistently stored vectorizers from the train phase to convert the tokens to the vectorized representations. The models are loaded as well and classification is performed to obtain the predictions as a simple array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movie-plots-student.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(df)) < 0.8\n",
    "train = df[mask]\n",
    "val = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8546, 3), (2170, 3))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drama</td>\n",
       "      <td>A Bill of Divorcement describes a day in the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Dr. Clitterhouse (Edward G. Robinson) is a wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Three young couples, all having financial stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Hollywood studio mogul Joe Mulholland (Matthau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>drama</td>\n",
       "      <td>In a working class South London district lives...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Genre                                               Plot\n",
       "0           0   drama  A Bill of Divorcement describes a day in the l...\n",
       "1           1  comedy  Dr. Clitterhouse (Edward G. Robinson) is a wea...\n",
       "2           2  comedy  Three young couples, all having financial stru...\n",
       "3           3  comedy  Hollywood studio mogul Joe Mulholland (Matthau...\n",
       "4           4   drama  In a working class South London district lives..."
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min  39\n",
      "Max  33033\n",
      "Mean  2104.7892581324595  Std  1738.3117201057998\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the shortest and the longest lyrics:\n",
    "min_plot = train[train[\"Plot\"].apply(lambda x: len(x))==train[\"Plot\"].apply(lambda x: len(x)).min()]\n",
    "max_plot = train[train[\"Plot\"].apply(lambda x: len(x))==train[\"Plot\"].apply(lambda x: len(x)).max()]\n",
    "print(\"Min \", len(\" \".join(min_plot[\"Plot\"].iloc[0])))\n",
    "print(\"Max \", len(\" \".join(max_plot[\"Plot\"].iloc[0])))\n",
    "lengths = [len(row[\"Plot\"]) for i, row in train.iterrows()]\n",
    "mean_len = np.mean(lengths)\n",
    "std_len = np.std(lengths)\n",
    "print(\"Mean \", mean_len, \" Std \", std_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8251, 3)\n"
     ]
    }
   ],
   "source": [
    "train=train[train[\"Plot\"].apply(lambda x: len(x)<=mean_len+2*std_len)]\n",
    "train=train[train[\"Plot\"].apply(lambda x: len(x)>=mean_len-2*std_len)]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 0, 'drama': 1, 'horror': 2, 'comedy': 3}\n"
     ]
    }
   ],
   "source": [
    "train_texts = train[\"Plot\"]\n",
    "train_labels = train[\"Genre\"]\n",
    "ref = pickle.load(open(\"ref.pkl\", \"rb\"))\n",
    "train_labels = [ref[label] for label in list(train[\"Genre\"])]\n",
    "print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = list(val[\"Plot\"])\n",
    "val_labels = list(val[\"Genre\"])\n",
    "val_labels = [ref[label] for label in list(val[\"Genre\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_proper_nouns(text):\n",
    "    tagged_sentence = nltk.tag.pos_tag(text.split())\n",
    "    edited_sentence = [word if tag != 'NNP' and tag != 'NNPS' else \"NNP\" for word,tag in tagged_sentence]\n",
    "    return ' '.join(edited_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [remove_proper_nouns(i) for i in train_texts]\n",
    "val_texts = [remove_proper_nouns(i) for i in val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens=[[token for token in nltk.tokenize.word_tokenize(text) if token.isalpha()] for text in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tokens=[[token for token in nltk.tokenize.word_tokenize(text) if token.isalpha()] for text in val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "train_tokens=[[token for token in doc if token not in stopwords.words(\"english\") and token!='NNP'] for doc in train_tokens]\n",
    "val_tokens=[[token for token in doc if token not in stopwords.words(\"english\") and token!='NNP'] for doc in val_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer\n",
    "porter=PorterStemmer()\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text in documents in three different ways:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizers={'binary':TfidfVectorizer(analyzer='word',binary=True),'bow':CountVectorizer(analyzer='word',binary=False),'tfidf':TfidfVectorizer(analyzer='word',binary=False)}\n",
    "vec_train_X,vec_val_X={},{}\n",
    "for name,vectorizer in vectorizers.items():\n",
    "    vec_train_X[name]=vectorizer.fit_transform([\" \".join(doc) for doc in train_tokens])\n",
    "    vec_val_X[name]=vectorizer.transform([\" \".join(doc) for doc in val_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Note the type of vectorization:\n",
    "print(type(vec_train_X['binary']))\n",
    "print(type(vec_train_X['bow']))\n",
    "print(type(vec_train_X['tfidf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary BernoulliNB()\n",
      "bow MultinomialNB()\n",
      "tfidf MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "# Create and fit three NB models:\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "models={'binary':BernoulliNB(),'bow':MultinomialNB(),'tfidf':MultinomialNB()}\n",
    "predictions={}\n",
    "for name,model in models.items():\n",
    "    print(name, model)\n",
    "    model.fit(vec_train_X[name],train_labels)\n",
    "    predictions[name]=model.predict(vec_val_X[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6132    0.3779    0.4676       172\n",
      "           1     0.6224    0.7894    0.6961      1040\n",
      "           2     0.5321    0.7015    0.6052       201\n",
      "           3     0.7188    0.4557    0.5578       757\n",
      "\n",
      "    accuracy                         0.6323      2170\n",
      "   macro avg     0.6216    0.5811    0.5817      2170\n",
      "weighted avg     0.6469    0.6323    0.6213      2170\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6510    0.5640    0.6044       172\n",
      "           1     0.7263    0.7808    0.7525      1040\n",
      "           2     0.7639    0.8209    0.7914       201\n",
      "           3     0.7234    0.6565    0.6884       757\n",
      "\n",
      "    accuracy                         0.7240      2170\n",
      "   macro avg     0.7162    0.7055    0.7092      2170\n",
      "weighted avg     0.7228    0.7240    0.7220      2170\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       172\n",
      "           1     0.5143    0.9827    0.6753      1040\n",
      "           2     0.0000    0.0000    0.0000       201\n",
      "           3     0.8415    0.2034    0.3277       757\n",
      "\n",
      "    accuracy                         0.5419      2170\n",
      "   macro avg     0.3390    0.2965    0.2507      2170\n",
      "weighted avg     0.5401    0.5419    0.4379      2170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_labels, predictions['binary'], digits=4))\n",
    "print(classification_report(val_labels, predictions['bow'], digits=4))\n",
    "print(classification_report(val_labels, predictions['tfidf'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vectorizers, open(\"train-vectorizers.pkl\", \"wb\"))\n",
    "pickle.dump(models, open(\"train-models.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts):\n",
    "    texts = [remove_proper_nouns(i) for i in texts]\n",
    "    vectorizers = pickle.load(open(\"full-vectorizers.pkl\", \"rb\"))\n",
    "    models = pickle.load(open(\"full-models.pkl\", \"rb\"))\n",
    "    tokens=[[token for token in nltk.tokenize.word_tokenize(text) if token.isalpha()] for text in texts]\n",
    "    tokens=[[token for token in doc if token not in stopwords.words(\"english\")] for doc in tokens]\n",
    "    #tokens=[[porter.stem(token) for token in doc] for doc in tokens]\n",
    "    vec_X={}\n",
    "    for name, vectorizer in vectorizers.items():\n",
    "        vec_X[name]=vectorizer.transform([\" \".join(doc) for doc in tokens])\n",
    "    predictions={}\n",
    "    for name,model in models.items():\n",
    "        print(name, model)\n",
    "        predictions[name]=model.predict(vec_X[name])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary BernoulliNB()\n",
      "bow MultinomialNB()\n",
      "tfidf MultinomialNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.59      0.64       172\n",
      "           1       0.79      0.75      0.77      1040\n",
      "           2       0.84      0.79      0.81       201\n",
      "           3       0.70      0.79      0.74       757\n",
      "\n",
      "    accuracy                           0.75      2170\n",
      "   macro avg       0.76      0.73      0.74      2170\n",
      "weighted avg       0.75      0.75      0.75      2170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = predict(val_texts)\n",
    "print(classification_report(val_labels, preds['bow']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6377    0.5116    0.5677       172\n",
      "           1     0.6937    0.7644    0.7274      1040\n",
      "           2     0.8242    0.7463    0.7833       201\n",
      "           3     0.6676    0.6209    0.6434       757\n",
      "\n",
      "    accuracy                         0.6926      2170\n",
      "   macro avg     0.7058    0.6608    0.6804      2170\n",
      "weighted avg     0.6923    0.6926    0.6906      2170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model = LR(multi_class='multinomial', penalty='l2', max_iter=2000)\n",
    "log_model.fit(vec_train_X['bow'], train_labels)\n",
    "preds = log_model.predict(vec_val_X['bow'])\n",
    "print(classification_report(val_labels, preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.3837    0.4871       172\n",
      "           1     0.6761    0.8067    0.7356      1040\n",
      "           2     0.8873    0.6269    0.7347       201\n",
      "           3     0.6846    0.6222    0.6519       757\n",
      "\n",
      "    accuracy                         0.6922      2170\n",
      "   macro avg     0.7287    0.6099    0.6523      2170\n",
      "weighted avg     0.6979    0.6922    0.6866      2170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=5)\n",
    "svm.fit(vec_train_X['bow'], train_labels)\n",
    "preds = svm.predict(vec_val_X['bow'])\n",
    "print(classification_report(val_labels, preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.1163    0.2083       172\n",
      "           1     0.5961    0.9096    0.7202      1040\n",
      "           2     0.8738    0.4478    0.5921       201\n",
      "           3     0.7370    0.4478    0.5571       757\n",
      "\n",
      "    accuracy                         0.6429      2170\n",
      "   macro avg     0.8017    0.4804    0.5194      2170\n",
      "weighted avg     0.7030    0.6429    0.6109      2170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "rf = RF()\n",
    "rf.fit(vec_train_X['bow'], train_labels)\n",
    "preds = rf.predict(vec_val_X['bow'])\n",
    "print(classification_report(val_labels, preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
