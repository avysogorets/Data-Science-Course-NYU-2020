{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation Split\n",
    "\n",
    "To get a sense of how our models will generalize, we separate the data into the training set (`train_data`) and a validation set (`val_data`). We _only_ use the training set to compute the TF-IDF vectorization, and then use the statistics computed to get a transform on the validation data.\n",
    "\n",
    "We use approximately 20% of the dataset towards validation. Further, we use stratified sampling which\n",
    "ensures that our dataset split has roughly the same proportion of Genres (the output variable) as in the original dataset so as to not skew the original dataset further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('movie-plots-student.csv')[['Genre', 'Plot']]\n",
    "train_data, val_data = train_test_split(all_data, test_size=.2, stratify=all_data.Genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "We generate the features using TF-IDF vectorizer as the simplest approach and try to extract the maximum predictive power out of this featurization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='unicode', lowercase=True, stop_words='english')\n",
    "train_X = vectorizer.fit_transform(train_data.Plot.values.tolist())\n",
    "train_y = train_data.Genre.values.tolist()\n",
    "\n",
    "val_X = vectorizer.transform(val_data.Plot.values.tolist())\n",
    "val_y = val_data.Genre.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "In each of the following models, we report the \"Training Accuracy\" on `train_data` as defined earlier, \"Validation Accuracy\" on `val_data` as defined earlier, the macro F-1 score and the confusion matrix to get a sense of the classes where the classifier fails, with each row representing the true label and each column representing the predicted column. This means in a confusion matrix for a K-way classification task, $C \\in \\mathbb{Z}^{K\\times K}$, $C[i,j]$ represents the total number of inputs of class $i$ predicted as class $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=100)\n",
    "model.fit(train_X, train_y)\n",
    "print(f'Training Accuracy: {model.score(train_X, train_y)}')\n",
    "print(f'Validation Accuracy: {model.score(val_X, val_y)}')\n",
    "print(f'Macro F-1 Score: {f1_score(val_y, model.predict(val_X), average=\"macro\")}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(val_y, model.predict(val_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try a Random Forest classifier with a maximum tree depth of 100 using the `gini` criterion. While we are able to get significant train accuracy, we see that the classifier falters on misclassifying a lot of labels with class index 0 as class index 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=10, learning_rate=1.0)\n",
    "model.fit(train_X, train_y)\n",
    "print(f'Training Accuracy: {model.score(train_X, train_y)}')\n",
    "print(f'Validation Accuracy: {model.score(val_X, val_y)}')\n",
    "print(f'Macro F-1 Score: {f1_score(val_y, model.predict(val_X), average=\"macro\")}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(val_y, model.predict(val_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting classifier is able to improve upon the random forest classifier, especially in terms of the macro F-1 score, since it now makes more varied errors, instead of just in a single class. This is a consequence of the fact that the gradient boosting classifier focuses of creating subsequent estimators that improve misclassifications explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=1.0, kernel='rbf')\n",
    "model.fit(train_X, train_y)\n",
    "print(f'Training Accuracy: {model.score(train_X, train_y)}')\n",
    "print(f'Validation Accuracy: {model.score(val_X, val_y)}')\n",
    "print(f'Macro F-1 Score: {f1_score(val_y, model.predict(val_X), average=\"macro\")}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(val_y, model.predict(val_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector classifier trains one-vs-all classifiers, and is costly. Nevertheless, it is able to predict the train data well, while retaining much of the performance from gradient boosting classifiers. While, it may appear the we may have overfit, different settings of the margin parameter $C$ did not seem to improve the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=30)\n",
    "model.fit(train_X, train_y)\n",
    "print(f'Training Accuracy: {model.score(train_X, train_y)}')\n",
    "print(f'Validation Accuracy: {model.score(val_X, val_y)}')\n",
    "print(f'Macro F-1 Score: {f1_score(val_y, model.predict(val_X), average=\"macro\")}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(val_y, model.predict(val_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nearest-neighbor classifier is among the worst performing classifiers. This is potentially due to the fact that the inputs are very high-dimensional. Since, in a high-dimensional space, the Euclidean distance suffers from the curse of dimensionality, and most vectors are very close to each other, a nearest neighbor classifier is not able to distinguish signficantly between the various vectors. This is the reason for a signficantly lower training and validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=2.)\n",
    "model.fit(train_X, train_y)\n",
    "print(f'Training Accuracy: {model.score(train_X, train_y)}')\n",
    "print(f'Validation Accuracy: {model.score(val_X, val_y)}')\n",
    "print(f'Macro F-1 Score: {f1_score(val_y, model.predict(val_X), average=\"macro\")}')\n",
    "print(f'Confusion Matrix:\\n{confusion_matrix(val_y, model.predict(val_X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is our best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data):\n",
    "    '''Test the model.\n",
    "    We assume `test_data` is a list of strings.\n",
    "    '''\n",
    "    return model.predict(vectorizer.transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"movie-plots-test.csv\",index_col=0)\n",
    "test_y=data[\"Genre\"]\n",
    "preds=test_model(data[\"Plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import classification_report as cr\n",
    "cm(test_y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr(test_y,preds))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
