{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Preprocessing data\n",
    "    data=pd.read_csv('movie-plots-student.csv')\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('/',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('\\r',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('\\n',' '))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('/s',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('.',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(',',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(':',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(';',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"!\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"?\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"-\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"_\",' '))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"'\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('\"',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('(',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\")\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('[',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"]\",''))\n",
    "\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('0',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('1',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('2',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('3',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"4\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('5',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('6',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"7\",''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace('8',''))\n",
    "    data[\"Plot\"]=data[\"Plot\"].apply(lambda x: x.replace(\"9\",''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #preprocessing labels\n",
    "    genres = ['comedy', 'drama', 'horror', 'action']\n",
    "    labels = np.zeros(len(data[\"Genre\"]), dtype='int8')\n",
    "    labels[data[\"Genre\"] == \"comedy\"] = 0\n",
    "    labels[data[\"Genre\"] == \"drama\"] = 1\n",
    "    labels[data[\"Genre\"] == \"horror\"] = 2\n",
    "    labels[data[\"Genre\"] == \"action\"] = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Removing stop words \n",
    "    new_text_data = []\n",
    "    text_data = data[\"Plot\"].values.tolist()\n",
    "    wnl=WordNetLemmatizer()\n",
    "    tokens_full=[[wnl.lemmatize(token.lower()) for token in nltk.tokenize.word_tokenize(text.lower()) if token.isalpha()] for text in text_data]\n",
    "   \n",
    "    #STOPWORDS\n",
    "    counter=Counter(np.concatenate(tokens_full))\n",
    "    word_freq=counter.most_common(250)\n",
    "    my_stop_words =[w[0] for w in word_freq]     \n",
    "    my_stop_words += stopwords.words('english') + ['a', 'the']\n",
    "\n",
    "\n",
    "    for doc in tqdm(text_data):\n",
    "\n",
    "        token_i =[token.lower() for token in doc.split(' ') if token.lower() not in my_stop_words]\n",
    "        new_text = \" \".join(token_i)\n",
    "        new_text_data.append(new_text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10716/10716 [00:14<00:00, 750.35it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Vectorize text in documents in three different ways:\n",
    "    vectorizers={'binary':TfidfVectorizer(analyzer='word',binary=True),'bow':CountVectorizer(analyzer='word',binary=False),'tfidf':TfidfVectorizer(analyzer='word',binary=False)}\n",
    "    X = {} \n",
    "    for i, (name,vectorizer) in enumerate(vectorizers.items()):\n",
    "        X[name]=vectorizer.fit_transform(new_text_data)\n",
    "\n",
    "    assert len(labels) == len(data), 'label and data length do not match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "    # Train/Test split of the data and labels:\n",
    "    train=np.random.choice(range(len(labels)),size=int(0.8*len(labels)),replace=False)\n",
    "    train_y=[labels[i] for i in train]\n",
    "\n",
    "    test=[i for i in range(len(labels)) if i not in train]\n",
    "    test_y=[labels[i] for i in test]\n",
    "\n",
    "    vec_train_X,vec_test_X={},{}\n",
    "    vec_train_X['binary'] = X['binary'][train]\n",
    "    vec_train_X['bow']  = X['bow'][train]\n",
    "    vec_train_X['tfidf'] = X['tfidf'][train]\n",
    "    vec_test_X['binary'] = X['binary'][test]\n",
    "    vec_test_X['bow']   = X['bow'][test]\n",
    "    vec_test_X['tfidf'] = X['tfidf'][test]\n",
    "\n",
    "\n",
    "    # Note the type of vectorization:\n",
    "    print(type(vec_train_X['binary']))\n",
    "    print(type(vec_train_X['bow']))\n",
    "    print(type(vec_train_X['tfidf']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Model fitting\n",
    "    models={'binary':BernoulliNB(),'bow':MultinomialNB(),'tfidf':MultinomialNB()}\n",
    "    predictions={}\n",
    "    for name,model in models.items():\n",
    "        model.fit(vec_train_X[name],train_y)\n",
    "        predictions[name]=model.predict(vec_test_X[name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  true comedy  true drama  true horror  true action\n",
      "predicted comedy          334          89           18           27\n",
      "predicted drama           384         899           94          115\n",
      "predicted horror            8          19          102            3\n",
      "predicted action            4          11            0           37\n",
      "0.5449413366596612\n",
      "                  true comedy  true drama  true horror  true action\n",
      "predicted comedy          514         241           24           36\n",
      "predicted drama           170         705           31           42\n",
      "predicted horror           13          18          153            7\n",
      "predicted action           33          54            6           97\n",
      "0.6649063421875117\n"
     ]
    }
   ],
   "source": [
    "    # Generate confusion matrices:\n",
    "    cms={name:pd.DataFrame(confusion_matrix(test_y,predictions[name]).T,index=[f\"predicted {genres[0]}\",f\"predicted {genres[1]}\",f\"predicted {genres[2]}\",f\"predicted {genres[3]}\"],columns=[f\"true {genres[0]}\",f\"true {genres[1]}\",f\"true {genres[2]}\",f\"true {genres[3]}\"]) for name in predictions.keys()}\n",
    "    f1_binary = f1_score(test_y, predictions['binary'], average='macro')\n",
    "    print(cms[\"binary\"])\n",
    "    print(f1_binary)\n",
    "\n",
    "    f1_bow = f1_score(test_y, predictions['bow'], average='macro')\n",
    "    print(cms[\"bow\"])\n",
    "    print(f1_bow)\n",
    "    \n",
    "    f1_tfidf = f1_score(test_y, predictions['tfidf'], average='macro')\n",
    "    print(cms[\"tfidf\"])\n",
    "    print(f1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ONE IS BOW WITH F1 0.664906\n"
     ]
    }
   ],
   "source": [
    "print(\"BEST ONE IS BOW WITH F1 %f\" % f1_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
