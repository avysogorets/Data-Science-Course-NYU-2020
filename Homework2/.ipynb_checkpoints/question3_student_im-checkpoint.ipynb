{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 3*\n",
    "The five datafiles ```rpl17.html```, ```rpl18.html```, ```rpl19.html```, ```rpl20.html```, ```rpl21.html``` contain detailed statistics on soccer matches of the last five seasons of the Russian Premier League (the 2021 season is currently in play). Among other statistics, each table includes information about: goals, yellow cards, red cards, shots, shots on target, pre-match bookmaker odds, possession, etc., each for both home and away teams. Check [this webpage](ttps://footystats.org/download-stats-csv) for a more detailed explanation of features in each table. Your task will be to prepare data for Question 4 by completing the function below. In particular, it should\n",
    "\n",
    "#####  ```process_season(filename,window):```\n",
    " 1. drop any incomplete matches (note the ```status``` column);\n",
    " 2. drop all features not listed in ```features``` defined in line 3;\n",
    " 3. rename those features to ```new_features``` defined in line 4;\n",
    " 4. add the ```outcome``` feature indicating if the match ended in a home win (1), draw (0), or a home loss (-1);\n",
    " 5. make sure that rows are sorted in temporal order (note the ```timestamp``` column);\n",
    " 6. add two more features to your data: ```H_miss``` and ```A_miss``` (the number of goals conceded by home and away teams, respectively);\n",
    " 7. note that the ```ppg``` column (average points earned per game prior to the current match) does not always contain the correct value; recompute this column based on information from other columns in the data (recall that in soccer, wins, draws and losses bring 3, 1, and 0 points, respectively);\n",
    " 8. drop all rows with implausible column values; i.e., numeric statistics for home and away teams (```H_``` and ```A_``` prefixed columns except for the team names) should never be negative, while the bookmaker odds (```win```, ```draw```,```loss```) should all be at least 1. Entries violating these rules are most probably indications of missing data.\n",
    " 9. for each match, replace the numeric statistics for home and away teams (```H_``` and ```A_``` prefixed columns) with their average in the previous ```window``` (e.g., 5) matches of each of these two teams. For example, the row corresponding to the match \"Krasnodar\"-\"Zenit\" (the first team listed is always the home team by default) should have the average number of yellow cards earned by \"Krasnodar\" and \"Zenit\" in their last ```window``` matches in the league in columns ```H_ycards``` and ```A_ycards```, respectively. This procedure is necessary since we don't have access to match statistics before it is played, so the model in Question 4 will have to base its predictions on the running average perfromance of the teams playing.\n",
    " 10. return the resulting Pandas DataFrame.\n",
    " \n",
    "After this function is ready, the remaining cells in this file will aggregate data across seasons, then split, normalize, and save it. Run these cells as you will need this data for Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_season(filename,window):\n",
    "    data=pd.read_csv(filename)\n",
    "    features=[\"home_team_name\",\"away_team_name\",\"Pre-Match PPG (Home)\",\"Pre-Match PPG (Away)\",\"home_team_goal_count\",\"away_team_goal_count\",\"home_team_corner_count\",\"away_team_corner_count\",\"home_team_yellow_cards\",\"home_team_red_cards\",\"away_team_yellow_cards\",\"away_team_red_cards\",\"home_team_first_half_cards\",\"away_team_first_half_cards\",\"home_team_shots\",\"away_team_shots\",\"home_team_shots_on_target\",\"away_team_shots_on_target\",\"home_team_fouls\",\"away_team_fouls\",\"home_team_possession\",\"away_team_possession\",\"odds_ft_home_team_win\",\"odds_ft_draw\",\"odds_ft_away_team_win\"]\n",
    "    features_new=[\"H_team\",\"A_team\",\"H_ppg\",\"A_ppg\",\"H_score\",\"A_score\",\"H_corners\",\"A_corners\",'H_ycards', 'H_rcards',\"A_ycards\",\"A_rcards\",\"H_htcards\",\"A_htcards\",\"H_shots\",\"A_shots\",\"H_shotst\",\"A_shotst\",\"H_fouls\",\"A_fouls\",\"H_pos\",\"A_pos\",\"win\",\"draw\",\"loss\"]\n",
    "\n",
    "    # TO DO\n",
    "    #drop any incomplete matches (note the status column);\n",
    "    data = data[data['status'] == 'complete']\n",
    "    \n",
    "    mask = (data['odds_ft_home_team_win'] + data['odds_ft_draw'] + data['odds_ft_away_team_win']) > 1\n",
    "    data = data[mask].copy()\n",
    " \n",
    "    \n",
    "    #make sure that rows are sorted in temporal order (note the timestamp column);\n",
    "    data = data.sort_values(by=['timestamp'])\n",
    "    \n",
    "    #add the outcome feature indicating if the match ended in a home win (1), draw (0), or a home loss (-1);\n",
    "    mask = data['home_team_goal_count'] - data['away_team_goal_count'] \n",
    "    maskp1 = np.argwhere(mask > 0 ).flatten()\n",
    "    mask0  = np.argwhere(mask == 0).flatten()\n",
    "    maskm1 = np.argwhere(mask < 0 ).flatten()\n",
    "    target = np.zeros(mask.shape[0])\n",
    "    target[maskp1] = 1\n",
    "    target[mask0] = 0\n",
    "    target[maskm1] = -1\n",
    "\n",
    "    #drop all features not listed in features defined in line 3;\n",
    "    data_ = data[features]\n",
    "    \n",
    "    #rename those features to new_features defined in line 4;\n",
    "    rename = {key:value for key,value in zip(features, features_new)}\n",
    "    data_ = data_.rename(columns=rename)\n",
    "    \n",
    "    #add two more features to your data: H_miss and A_miss (the number of goals conceded by home and away teams, respectively);\n",
    "    data_[\"H_miss\"] = data['away_team_goal_count']\n",
    "    data_[\"A_miss\"] = data['home_team_goal_count']\n",
    "    \n",
    "    if len(data_) > 0:\n",
    "        nanindex = data_.notna().any(axis=1).values\n",
    "        data_ = data_[nanindex]\n",
    "        target = target[nanindex]\n",
    "    \n",
    "    print(filename, data_.shape, target.shape)\n",
    "    #data_.dropna()\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #tmp = np.sum(data['odds_ft_home_team_win'] + data['odds_ft_draw'] + data['odds_ft_away_team_win'])\n",
    "    \n",
    "    #note that the ppg column (average points earned per game prior to the current match) does not always contain the correct value; recompute this column based on information from other columns in the data (recall that in soccer, wins, draws and losses bring 3, 1, and 0 points, respectively);\n",
    "    teams = set(data['home_team_name'].unique().tolist() + data['away_team_name'].unique().tolist())\n",
    "    for row in data_.index:\n",
    "        xx = data_.loc[row]\n",
    "        team_name_h = xx['H_team']\n",
    "        team_name_a = xx['A_team']\n",
    "        \n",
    "        def get_pgg(team_name):\n",
    "            num_win, num_tie, num_lose = 0, 0, 0\n",
    "            for attr in ['H_team', 'A_team']:\n",
    "                filter_ind = (team_name ==data_[attr]) & (data_.index < row)\n",
    "                filtered_data = data_[filter_ind]\n",
    "\n",
    "                h_score_ = filtered_data[\"H_score\"].values\n",
    "                a_score_ = filtered_data[\"A_score\"].values\n",
    "                len_fdata = len(filtered_data)\n",
    "                if len_fdata > 0:\n",
    "                    count_h = np.sum(h_score_ > a_score_)\n",
    "                    if attr == 'H_team':\n",
    "                        num_win += count_h / len_fdata\n",
    "                    else:\n",
    "                        num_lose += count_h / len_fdata\n",
    "\n",
    "                    count_a = np.sum(h_score_ < a_score_)\n",
    "                    if attr == 'A_team':\n",
    "                        num_win += count_a / len_fdata\n",
    "                    else:\n",
    "                        num_lose += count_a / len_fdata\n",
    "\n",
    "                    count_t = np.sum(h_score_ == a_score_)\n",
    "                    num_tie += count_t /len_fdata\n",
    "            return num_win, num_tie, num_lose\n",
    "    \n",
    "        def get_running_avg(team_name, side):\n",
    "            \n",
    "            filter_ind_h = (team_name ==data_cp['H_team']) & (data_cp.index < row)\n",
    "            filtered_data_h = data_cp[filter_ind_h]\n",
    "            filter_ind_a = (team_name ==data_cp['A_team']) & (data_cp.index < row)\n",
    "            filtered_data_a = data_cp[filter_ind_a]\n",
    "            feat_tmp, h_features, a_features = [], [], []\n",
    "            for feat in  data_cp.keys():\n",
    "                if feat.startswith('H_'):\n",
    "                    feat_tmp.append(feat[2:])\n",
    "                    h_features.append(feat)\n",
    "                elif feat.startswith('A_'):\n",
    "                    a_features.append(feat)\n",
    "\n",
    "            filtered_data_h = filtered_data_h[h_features]\n",
    "            filtered_data_a = filtered_data_a[a_features]\n",
    "            rename_h = {key:value for key,value in zip(h_features, feat_tmp)}\n",
    "            rename_a = {key:value for key,value in zip(a_features, feat_tmp)}\n",
    "            filtered_data_h = filtered_data_h.rename(columns=rename_h)\n",
    "            filtered_data_a = filtered_data_a.rename(columns=rename_a)\n",
    "            filtered_data_n = filtered_data_h.append(filtered_data_a)\n",
    "            ind_h = np.argwhere(filter_ind_h).flatten()\n",
    "            ind_a = np.argwhere(filter_ind_a).flatten()\n",
    "            ind_ = np.hstack([ind_h, ind_a])\n",
    "            sorted_ind = np.argsort(ind_)\n",
    "            if side == 'home':\n",
    "                rename_h = {key:value for key,value in zip(feat_tmp,h_features)}\n",
    "                filtered_data_n = filtered_data_n.rename(columns=rename_h)\n",
    "                avg_feat = filtered_data_n.iloc[sorted_ind[-5:]].mean(0)\n",
    "                avg_feat[np.isnan(avg_feat)] = 0\n",
    "                return avg_feat, h_features\n",
    "            else:\n",
    "                rename_a = {key:value for key,value in zip(feat_tmp,a_features)}\n",
    "                filtered_data_n = filtered_data_n.rename(columns=rename_a)\n",
    "                avg_feat = filtered_data_n.iloc[sorted_ind[-5:]].mean(0)\n",
    "                avg_feat[np.isnan(avg_feat)] = 0\n",
    "                return avg_feat, a_features\n",
    "\n",
    "        num_win, num_tie, num_lose = get_pgg(team_name_h)\n",
    "        data_.loc[row,\"H_ppg\"] = num_win * 3 + num_tie \n",
    "        num_win, num_tie, num_lose = get_pgg(team_name_a)\n",
    "        data_.loc[row,\"A_ppg\"] = num_win * 3 + num_tie \n",
    "        \n",
    "        \n",
    "        #Drop all rows with implausible column values; i.e., numeric statistics for home and away teams (H_ and A_ prefixed columns except for the team names) should never be negative, while the bookmaker odds (win, draw,loss) should all be at least 1. Entries violating these rules are most probably indications of missing data.\n",
    "        #filter_H_ = [col for col in features if col.startswith('H_')]\n",
    "        #filter_A_ = [col for col in features if col.startswith('A_')]\n",
    "        #data_.drop(data_[data_[filter_H_] < 25].index, inplace = True)\n",
    "        #data_.drop(data_[data_[filter_A_] < 25].index, inplace = True)\n",
    "        \n",
    "        data_cp = data_.copy()\n",
    "        avg_feat_h, h_features = get_running_avg(team_name_h, 'home')\n",
    "        avg_feat_a, a_features = get_running_avg(team_name_a, 'away')\n",
    "        data_.loc[row, h_features] = avg_feat_h\n",
    "        data_.loc[row, a_features] = avg_feat_a\n",
    "        data_.loc[row, 'H_team'] = team_name_h\n",
    "        data_.loc[row, 'A_team'] = team_name_a\n",
    "     \n",
    "    assert (target.shape[0] == data_.shape[0]), 'target and data shape mismatch'\n",
    "    data_['outcome'] = target\n",
    "    return data_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 1, index implies 96.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7d333fd5817d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_season\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rpl21.html\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-1246a9a2dea3>\u001b[0m in \u001b[0;36mprocess_season\u001b[0;34m(filename, window)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#add the outcome feature indicating if the match ended in a home win (1), draw (0), or a home loss (-1);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'home_team_goal_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'away_team_goal_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmaskp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmask0\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmaskm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36margwhere\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;31m# then remove the added dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \"\"\"\n\u001b[0;32m-> 1896\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nonzero'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   1785\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m         return self._constructor(result, **d).__finalize__(\n\u001b[0m\u001b[1;32m   1788\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"__array_wrap__\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    314\u001b[0m                             \u001b[0;34mf\"Length of passed values is {len(data)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                             \u001b[0;34mf\"index implies {len(index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 1, index implies 96."
     ]
    }
   ],
   "source": [
    "process_season(\"rpl21.html\",5).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpl17.csv (0, 27) (0,)\n",
      "rpl17.csv (0, 28)\n",
      "rpl18.csv (85, 27) (85,)\n",
      "rpl18.csv (85, 28)\n",
      "rpl19.csv (230, 27) (230,)\n",
      "rpl19.csv (315, 28)\n",
      "rpl20.csv (236, 27) (236,)\n",
      "rpl20.csv (551, 28)\n",
      "rpl21.csv (96, 27) (96,)\n",
      "rpl21.csv (647, 28)\n",
      "(647, 28)\n"
     ]
    }
   ],
   "source": [
    "# Process each league and concatenate datasets (run this):\n",
    "filenames=[f'rpl{season}.csv' for season in range(17,22)]\n",
    "data=pd.DataFrame()\n",
    "for file in filenames:\n",
    "    data=pd.concat([data,process_season(file,5)],ignore_index=True)\n",
    "    print(file, data.shape)\n",
    "data=data.reindex()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 28)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "# Specify predictors and the target (run this):\n",
    "features=[x for x in data.columns if x not in [\"H_team\",\"A_team\",\"outcome\"]]\n",
    "target=\"outcome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (80/20) and MinMax transform the data (run this):\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train=np.random.choice(range(len(data)),size=int(0.8*len(data)),replace=False)\n",
    "test=[x for x in data.index if x not in train]\n",
    "train_X,train_y=data.loc[train,features],data.loc[train,target]\n",
    "test_X,test_y=data.loc[test,features],data.loc[test,target]\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "train_X=scaler.fit_transform(train_X)\n",
    "test_X=scaler.transform(test_X)\n",
    "np.save(\"train_X2.npy\",train_X)\n",
    "np.save(\"train_y2.npy\",train_y)\n",
    "np.save(\"test_X2.npy\",test_X)\n",
    "np.save(\"test_y2.npy\",test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
