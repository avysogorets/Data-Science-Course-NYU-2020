{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 3*\n",
    "The five datafiles ```rpl17.html```, ```rpl18.html```, ```rpl19.html```, ```rpl20.html```, ```rpl21.html``` contain detailed statistics on soccer matches of the last five seasons of the Russian Premier League (the 2021 season is currently in play). Among other statistics, each table includes information about: goals, yellow cards, red cards, shots, shots on target, pre-match bookmaker odds, possession, etc., each for both home and away teams. Check [this webpage](ttps://footystats.org/download-stats-csv) for a more detailed explanation of features in each table. Your task will be to prepare data for Question 4 by completing the function below. In particular, it should\n",
    "\n",
    "#####  ```process_season(filename,window):```\n",
    " 1. drop any incomplete matches (note the ```status``` column);\n",
    " 2. drop all features not listed in ```features``` defined in line 3;\n",
    " 3. rename those features to ```new_features``` defined in line 4;\n",
    " 4. add the ```outcome``` feature indicating if the match ended in a home win (1), draw (0), or a home loss (-1);\n",
    " 5. make sure that rows are sorted in temporal order (note the ```timestamp``` column);\n",
    " 6. add two more features to your data: ```H_miss``` and ```A_miss``` (the number of goals conceded by home and away teams, respectively);\n",
    " 7. note that the ```ppg``` column (average points earned per game prior to the current match) does not always contain the correct value; recompute this column based on information from other columns in the data (recall that in soccer, wins, draws and losses bring 3, 1, and 0 points, respectively);\n",
    " 8. drop all rows with implausible column values; i.e., numeric statistics for home and away teams (```H_``` and ```A_``` prefixed columns except for the team names) should never be negative, while the bookmaker odds (```win```, ```draw```,```loss```) should all be at least 1. Entries violating these rules are most probably indications of missing data.\n",
    " 9. for each match, replace the numeric statistics for home and away teams (```H_``` and ```A_``` prefixed columns) with their average in the previous ```window``` (e.g., 5) matches of each of these two teams. For example, the row corresponding to the match \"Krasnodar\"-\"Zenit\" (the first team listed is always the home team by default) should have the average number of yellow cards earned by \"Krasnodar\" and \"Zenit\" in their last ```window``` matches in the league in columns ```H_ycards``` and ```A_ycards```, respectively. This procedure is necessary since we don't have access to match statistics before it is played, so the model in Question 4 will have to base its predictions on the running average perfromance of the teams playing.\n",
    " 10. return the resulting Pandas DataFrame.\n",
    " \n",
    "After this function is ready, the remaining cells in this file will aggregate data across seasons, then split, normalize, and save it. Run these cells as you will need this data for Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_season(filename,window):\n",
    "    data=pd.read_csv(filename)\n",
    "    features=[\"home_team_name\",\"away_team_name\",\"Pre-Match PPG (Home)\",\"Pre-Match PPG (Away)\",\"home_team_goal_count\",\"away_team_goal_count\",\"home_team_corner_count\",\"away_team_corner_count\",\"home_team_yellow_cards\",\"home_team_red_cards\",\"away_team_yellow_cards\",\"away_team_red_cards\",\"home_team_first_half_cards\",\"away_team_first_half_cards\",\"home_team_shots\",\"away_team_shots\",\"home_team_shots_on_target\",\"away_team_shots_on_target\",\"home_team_fouls\",\"away_team_fouls\",\"home_team_possession\",\"away_team_possession\",\"odds_ft_home_team_win\",\"odds_ft_draw\",\"odds_ft_away_team_win\"]\n",
    "    features_new=[\"H_team\",\"A_team\",\"H_ppg\",\"A_ppg\",\"H_score\",\"A_score\",\"H_corners\",\"A_corners\",'H_ycards', 'H_rcards',\"A_ycards\",\"A_rcards\",\"H_htcards\",\"A_htcards\",\"H_shots\",\"A_shots\",\"H_shotst\",\"A_shotst\",\"H_fouls\",\"A_fouls\",\"H_pos\",\"A_pos\",\"win\",\"draw\",\"loss\"]\n",
    "    \n",
    "    # TO DO\n",
    "    \n",
    "    # Solution:\n",
    "    data=data.loc[data[\"status\"]==\"complete\",:]\n",
    "    data.sort_values(\"timestamp\",axis=0,ascending=True,inplace=True)\n",
    "    data=data[features]\n",
    "    data.rename(columns={old:new for old,new in zip(data.columns,features_new)},inplace=True)\n",
    "    data.drop(index=set(x for inds_col in [data[data[col]<0].index.to_list() for col in data.columns[2:-3]] for x in inds_col),inplace=True)\n",
    "    data.drop(index=set(x for inds_col in [data[data[col]<1].index.to_list() for col in data.columns[-3:]] for x in inds_col),inplace=True)\n",
    "    teams=set(np.concatenate([data[\"H_team\"].unique(),data[\"A_team\"].unique()]))\n",
    "    data[\"H_miss\"]=data[\"A_score\"]\n",
    "    data[\"A_miss\"]=data[\"H_score\"]\n",
    "    data[\"outcome\"]=[1 if h_score>a_score else 0 if h_score==a_score else -1 for h_score,a_score in zip(data[\"H_score\"],data[\"A_score\"])]\n",
    "    features_home=[feature for feature in data.columns if feature[0]=='H']\n",
    "    features_away=[feature for feature in data.columns if feature[0]=='A']\n",
    "    teams_data_home={team:data[data[\"H_team\"]==team].drop([f for f in data.columns if f not in features_home],axis=1) for team in teams}\n",
    "    teams_data_away={team:data[data[\"A_team\"]==team].drop([f for f in data.columns if f not in features_away],axis=1) for team in teams}\n",
    "    teams_data={team:pd.concat([teams_data_home[team].rename(columns={col:col[2:] for col in teams_data_home[team].columns if col[0]=='H'}),teams_data_away[team].rename(columns={col:col[2:] for col in teams_data_away[team].columns if col[0]=='A'})]).sort_index() for team in teams}\n",
    "    indices_to_drop=set()\n",
    "    for team in teams:\n",
    "        teams_data[team][\"ppg\"]=3*teams_data[team][\"score\"].gt(teams_data[team][\"miss\"]).astype(int)\n",
    "        teams_data[team][\"ppg\"]+=teams_data[team][\"score\"].eq(teams_data[team][\"miss\"]).astype(int)\n",
    "        teams_data[team].iloc[:,1:]=teams_data[team].iloc[:,1:].rolling(window).mean().shift(periods=1)\n",
    "        to_drop=teams_data[team].index[:window].to_list()\n",
    "        teams_data[team].drop(index=to_drop,inplace=True)\n",
    "        indices_to_drop.update(to_drop)\n",
    "    data.drop(index=indices_to_drop,inplace=True)\n",
    "    for ind in data.index:\n",
    "        data.loc[ind,features_home]=teams_data[data.loc[ind,\"H_team\"]].add_prefix('H_').loc[ind,:]\n",
    "        data.loc[ind,features_away]=teams_data[data.loc[ind,\"A_team\"]].add_prefix('A_').loc[ind,:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each league and concatenate datasets (run this):\n",
    "filenames=[f'rpl{season}.html' for season in range(17,22)]\n",
    "data=pd.DataFrame()\n",
    "for file in filenames:\n",
    "    data=pd.concat([data,process_season(file,5)],ignore_index=True)\n",
    "data=data.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify predictors and the target (run this):\n",
    "features=[x for x in data.columns if x not in [\"H_team\",\"A_team\",\"outcome\"]]\n",
    "target=\"outcome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (80/20) and MinMax transform the data (run this):\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train=np.random.choice(range(len(data)),size=int(0.8*len(data)),replace=False)\n",
    "test=[x for x in data.index if x not in train]\n",
    "train_X,train_y=data.loc[train,features],data.loc[train,target]\n",
    "test_X,test_y=data.loc[test,features],data.loc[test,target]\n",
    "scaler=MinMaxScaler()\n",
    "train_X=scaler.fit_transform(train_X)\n",
    "test_X=scaler.transform(test_X)\n",
    "np.save(\"train_X.npy\",train_X)\n",
    "np.save(\"train_y.npy\",train_y)\n",
    "np.save(\"test_X.npy\",test_X)\n",
    "np.save(\"test_y.npy\",test_y)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
