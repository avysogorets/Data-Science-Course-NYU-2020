{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "train_X=np.load(\"train_X.npy\")\n",
    "train_y=np.load(\"train_y.npy\")>0\n",
    "test_X=np.load(\"test_X.npy\")\n",
    "test_y=np.load(\"test_y.npy\")>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(a)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 182\n",
      "116 188\n",
      "101 127\n",
      "49 103\n",
      "37 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-1cfe3a2b791e>:42: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  extra_y = new_tr_y[[new_tr_y == 1]][ran_ind]\n",
      "<ipython-input-2-1cfe3a2b791e>:43: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  extra_x = new_tr_x[[new_tr_y == 1]][ran_ind]\n"
     ]
    }
   ],
   "source": [
    "# Upsample the smaller class in the training data to ensure perfect\n",
    "# class balance. Then split it into 5 folds for cross-validation.\n",
    "# You should not use sklearn.\n",
    "\n",
    "# TO DO\n",
    "num_fold = 5\n",
    "N = train_y.shape[0]\n",
    "\n",
    "N_frac = N // 5\n",
    "cv, cvX, cvY = [], [], []\n",
    "for ifold in range(num_fold):\n",
    "    \n",
    "    ind2_start, ind2_end = (ifold+1)*N_frac,N\n",
    "    ind1_start, ind1_end = max((ifold-1)*N_frac,0), max(ifold*N_frac, 0)\n",
    "    if ind1_start != ind1_end and ind2_start != ind2_end:\n",
    "        new_tr_x = np.vstack([train_X[ind1_start:ind1_end], train_X[ind2_start:ind2_end]])\n",
    "        new_tr_y = np.hstack([train_y[ind1_start:ind1_end], train_y[ind2_start:ind2_end]])\n",
    "    elif ind1_start == ind1_end:\n",
    "        new_tr_x = train_X[ind2_start:ind2_end]\n",
    "        new_tr_y = train_y[ind2_start:ind2_end]\n",
    "    else:\n",
    "        new_tr_x = train_X[ind1_start:ind1_end]\n",
    "        new_tr_y = train_y[ind1_start:ind1_end]\n",
    "        \n",
    "    vl_x = train_X[ifold*N_frac:(ifold+1)*N_frac]\n",
    "    vl_y = train_y[ifold*N_frac:(ifold+1)*N_frac]\n",
    "    \n",
    "    \n",
    "    #Upsampling\n",
    "    num_ones = np.sum(new_tr_y == 1)\n",
    "    num_zeros = np.sum(new_tr_y == 0)\n",
    "    print(num_ones, num_zeros)\n",
    "    diff = num_ones - num_zeros\n",
    "    if num_ones > num_zeros:\n",
    "        ran_ind = np.random.randint(num_zeros, size=abs(diff))\n",
    "        extra_y = new_tr_y[[new_tr_y == 0]][ran_ind]\n",
    "        extra_x = new_tr_x[[new_tr_y == 0]][ran_ind]\n",
    "        new_tr_x = np.vstack([new_tr_x, extra_x])\n",
    "        new_tr_y = np.hstack([new_tr_y, extra_y])\n",
    "    else:\n",
    "        ran_ind = np.random.randint(num_ones, size=abs(diff))\n",
    "        extra_y = new_tr_y[[new_tr_y == 1]][ran_ind]\n",
    "        extra_x = new_tr_x[[new_tr_y == 1]][ran_ind]\n",
    "        new_tr_x = np.vstack([new_tr_x, extra_x])\n",
    "        new_tr_y = np.hstack([new_tr_y, extra_y])\n",
    "        \n",
    "    Ntr = len(new_tr_x)\n",
    "    perm_tr = np.random.permutation(Ntr)\n",
    "    new_tr_x = new_tr_x[perm_tr]\n",
    "    new_tr_y = new_tr_y[perm_tr]\n",
    "    #print(ind1_start, ind1_end, ind2_start, ind2_end)\n",
    "    cv.append([new_tr_x, new_tr_y, vl_x, vl_y])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(b)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from Homework 1:\n",
    "def sigmoid(t):\n",
    "    return 1./(1+np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the L2 regularization term to the old loss function: \n",
    "def compute_loss(X,y,theta,lam):\n",
    "    \n",
    "    # TO DO\n",
    "    # -sum([y_i*np.log(sigmoid(np.dot(theta,X_i)))+(1-y_i)*np.log(1-sigmoid(np.dot(theta,X_i))) for X_i,y_i in zip(X,y)])\n",
    "    pred = sigmoid(np.dot(X, theta))\n",
    "    loss = - np.mean( y * np.log(pred) + (1-y) * np.log(1-pred), axis=0)\n",
    "    #loss = - np.sum(np.dot(X.T,(y - )))\n",
    "    loss = loss + lam * np.sum(theta*theta)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the LogisticRegression class that supports regularization:\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self,alpha,max_iter,C,tolerance=1e-5):\n",
    "        self.lam=1/C\n",
    "        self.alpha=alpha\n",
    "        self.tolerance=tolerance\n",
    "        self.max_iter=max_iter\n",
    "        \n",
    "    def gradient(self,X,y):\n",
    "        \n",
    "        # TO DO\n",
    "        pred = sigmoid(np.dot(X, self.theta[0]))\n",
    "        grad = - np.sum(np.dot(y - pred, X),axis=0)\n",
    "        return grad + self.lam *2 * self.theta[0]\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        y=y.reshape((1,X.shape[0]))\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        self.theta=np.random.normal(loc=0,scale=1,size=X.shape[1]).reshape((1,X.shape[1]))\n",
    "        progress=[0,compute_loss(X,y[0],self.theta[0],self.lam)]\n",
    "        while self.max_iter>=0 and abs(progress[-1]-progress[-2])>self.tolerance:\n",
    "            self.theta-=self.alpha*self.gradient(X,y)\n",
    "            if self.max_iter%500==0:\n",
    "                loss = compute_loss(X,y[0],self.theta[0],self.lam)\n",
    "                progress.append(loss)\n",
    "                #print(self.max_iter, loss)\n",
    "            self.max_iter-=1\n",
    "        return progress[1:]\n",
    "    def margin(self,X):\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        return np.squeeze(np.matmul(self.theta,np.transpose(X)))\n",
    "    def predict(self,X,thresh):\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        return [1 if sigmoid(np.dot(self.theta,X_i))>thresh else 0 for X_i in X]\n",
    "    def proba(self,X):\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        return np.squeeze(np.array([sigmoid(np.dot(self.theta,X_i)) for X_i in X]))\n",
    "    \n",
    "#model = LogisticRegression(alpha=0.001,max_iter=10000,C=100000)\n",
    "#model.fit(train_X, train_y)\n",
    "#loss = compute_loss(train_X, train_y, model.theta[0], 0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2016x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Complete the below function. Arguments:\n",
    "# - models: K models from the K-fold cross-validation;\n",
    "# - XXs:    the corresponding validaton folds (features);\n",
    "# - yys:    the corresponding validaton folds (targets);\n",
    "# - label:  regularization constant (C);\n",
    "# - axis:   a subplot to be used for plotting;\n",
    "\n",
    "# The function should plot the ROC curve for each of the\n",
    "# models as well as their pointwise average (highlighted).\n",
    "# Moreover, plot the diagonal (0,0)-(1,1) as a dashed line\n",
    "# and print the mean AUC score.\n",
    "\n",
    "def validate_helper(models,XXs,yys,C, axis,ifold,colour):\n",
    "    \n",
    "    bookkeep = []\n",
    "    thrds = np.arange(11) * 0.1\n",
    "    prob = model.proba(XXs)\n",
    "    vmin,vmax = prob.min(), prob.max()\n",
    "    thrds = thrds * (vmax-vmin) + vmin\n",
    "    for thrd in thrds:\n",
    "        preds = model.predict(XXs,thrd)\n",
    "        preds = np.asarray(preds)\n",
    "        positive_mask = yys == 1\n",
    "        negative_mask = yys == 0\n",
    "        pred_pm = preds[positive_mask]\n",
    "        pred_pn = preds[negative_mask]\n",
    "    \n",
    "        TP = np.sum(pred_pm == yys[positive_mask])\n",
    "        FN = np.sum(pred_pm != yys[positive_mask])\n",
    "        FP = np.sum(pred_pn != yys[negative_mask])\n",
    "        TN = np.sum(pred_pn == yys[negative_mask])\n",
    "        \n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN )\n",
    "        bookkeep.append([TPR, FPR])\n",
    "    \n",
    "    fpr_array = []\n",
    "    tpr_array = []\n",
    "    for i in range(len(bookkeep)-1):\n",
    " \n",
    "        point1 = bookkeep[i];\n",
    "        point2 = bookkeep[i+1]\n",
    "        tpr_array.append([point1[0], point2[0]])\n",
    "        fpr_array.append([point1[1], point2[1]])\n",
    "        \n",
    "    \n",
    "    from sklearn import metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(yys, prob, pos_label=None)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    #auc = -sum(np.trapz(tpr_array,fpr_array))\n",
    "    bookkeep = np.asarray(bookkeep, dtype='float32').T\n",
    "    axis.plot(bookkeep[1], bookkeep[0], colour, label='Fold: %d' % ifold)\n",
    "    \n",
    "    \n",
    "    return bookkeep, auc, axis\n",
    "\n",
    "fig= plt.figure(figsize=(28,14))\n",
    "C=10000\n",
    "\n",
    "\n",
    "def validate(models,XXs,yys,C,axis):\n",
    "    num_fold=5\n",
    "    colours = ['r.-', 'b.-', 'g.-', 'k.-', 'y.-', 'm.-']\n",
    "    aucs, rocs = [], []\n",
    "    for ifold in range(num_fold):\n",
    "    \n",
    "        #crossvalid_data = cv[ifold]\n",
    "        #tr_X, tr_y, vl_X, vl_y = crossvalid_data\n",
    "        #model = LogisticRegression(alpha=0.001,max_iter=5000,C=C)\n",
    "        #model.fit(tr_X, tr_y)        \n",
    "        XX, yy = XXs[ifold], yys[ifold]\n",
    "        model = models[ifold]\n",
    "        bookkeep, auc, axis = validate_helper(model,XX,yy,C, axis,ifold, colours[ifold])\n",
    "        aucs.append(auc)\n",
    "        rocs.append(bookkeep)\n",
    "        \n",
    "    rocs = np.mean(np.asarray(rocs),axis=0)\n",
    "    axis.plot(rocs[1], rocs[0], colours[-1], label='Mean')\n",
    "    axis.set_title('AUC %f C %f' % (np.mean(aucs), C))\n",
    "    axis.set_ylim([0,1])\n",
    "    axis.legend()\n",
    "    \n",
    "    return np.mean(aucs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(d)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./figs/q4d.png\n"
     ]
    }
   ],
   "source": [
    "# Fit your logistic regression and apply the above\n",
    "\n",
    "# function to each selection of C. Which is the optimal value?\n",
    "fig,axes=plt.subplots(ncols=4,nrows=2,figsize=(17,9))\n",
    "Cs=[1e-2,1e-1,1,1e1,1e2,1e3,1e4,1e5]\n",
    "alphas = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "max_iter = [100, 250, 500, 1000,5000, 10000,50000,1000000]\n",
    "\n",
    "alpha = 0.00025\n",
    "search_list = Cs\n",
    "\n",
    "aucs = []\n",
    "for i, C in enumerate(search_list):\n",
    "    \n",
    "    models, XXs, yys = [], [], []\n",
    "    for ifold in range(num_fold):\n",
    "    \n",
    "        crossvalid_data = cv[ifold]\n",
    "        tr_X, tr_y, vl_X, vl_y = crossvalid_data\n",
    "        XXs.append(vl_X)\n",
    "        yys.append(vl_y)\n",
    "    \n",
    "        model = LogisticRegression(alpha=alpha,max_iter=20000,C=C)\n",
    "        model.fit(tr_X, tr_y)        \n",
    "        models.append(model)\n",
    "        \n",
    "    axis = axes[i%2][i // 2]\n",
    "    auc = validate(models,XXs,yys,C,axis)\n",
    "    aucs.append(auc)\n",
    "\n",
    "fname = 'q4d'\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figs/'+fname+'.png')\n",
    "print('./figs/'+fname+'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(e)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the below functions. The returned confusion matrix\n",
    "# should be a two-dimensional NumPy array.\n",
    "    \n",
    "def confusion_matrix(predictions,labels):\n",
    "    \n",
    "    positive_mask = labels == 1\n",
    "    negative_mask = labels == 0\n",
    "    pred_pm = predictions[positive_mask]\n",
    "    pred_pn = predictions[negative_mask]\n",
    "    \n",
    "\n",
    "    TP = np.sum(pred_pm == labels[positive_mask])\n",
    "    FN = np.sum(pred_pm != labels[positive_mask])\n",
    "    FP = np.sum(pred_pn != labels[negative_mask])\n",
    "    TN = np.sum(pred_pn == labels[negative_mask])\n",
    "    return [[TP, FP], [FN, TN]]\n",
    "    \n",
    "def precision(predictions,labels,pos_class=1):\n",
    "    \n",
    "    positive_mask = labels == 1\n",
    "    negative_mask = labels == 0\n",
    "    pred_pm = predictions[positive_mask]\n",
    "    pred_pn = predictions[negative_mask]\n",
    "    \n",
    "    TP = np.sum(pred_pm == labels[positive_mask])\n",
    "    FN = np.sum(pred_pm != labels[positive_mask])\n",
    "    FP = np.sum(pred_pn != labels[negative_mask])\n",
    "    TN = np.sum(pred_pn == labels[negative_mask])\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def recall(predictions,labels,pos_class=1):\n",
    "    \n",
    "    positive_mask = labels == 1\n",
    "    negative_mask = labels == 0\n",
    "    pred_pm = predictions[positive_mask]\n",
    "    pred_pn = predictions[negative_mask]\n",
    "    \n",
    "    TP = np.sum(pred_pm == labels[positive_mask])\n",
    "    FN = np.sum(pred_pm != labels[positive_mask])\n",
    "    FP = np.sum(pred_pn != labels[negative_mask])\n",
    "    TN = np.sum(pred_pn == labels[negative_mask])\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def f1_score(predictions,labels):\n",
    "    \n",
    "    p = precision(predictions,labels)\n",
    "    r = recall(predictions,labels)\n",
    "    return 2*p*r / (p + r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.582950352979712\n",
      "0.15000000000000002 0.6023962147379345\n",
      "0.20000000000000004 0.6056632755712547\n",
      "0.25000000000000006 0.5917251466415865\n",
      "0.30000000000000004 0.603282629066249\n",
      "0.3500000000000001 0.6086479411944208\n",
      "0.40000000000000013 0.5920177002220346\n",
      "0.45000000000000007 0.5912970632970633\n",
      "0.5000000000000001 0.5934206044962063\n",
      "0.5500000000000002 0.5518576097105509\n",
      "0.6000000000000002 0.489755355334103\n",
      "0.6500000000000001 0.4623538030596854\n",
      "0.7000000000000002 0.43052020882910674\n",
      "0.7500000000000002 0.3828303042416915\n",
      "0.8000000000000002 0.2959898682877406\n",
      "0.8500000000000002 0.22309178743961353\n",
      "[0.582950352979712, 0.6023962147379345, 0.6056632755712547, 0.5917251466415865, 0.603282629066249, 0.6086479411944208, 0.5920177002220346, 0.5912970632970633, 0.5934206044962063, 0.5518576097105509, 0.489755355334103, 0.4623538030596854, 0.43052020882910674, 0.3828303042416915, 0.2959898682877406, 0.22309178743961353]\n"
     ]
    }
   ],
   "source": [
    "# Select the appropriate threshold:\n",
    "thresh_vals=np.arange(0.1,0.9,0.05)\n",
    "C = 1000\n",
    "\n",
    "models, XXs, yys = [], [], []\n",
    "for ifold in range(num_fold):\n",
    "    \n",
    "    crossvalid_data = cv[ifold]\n",
    "    tr_X, tr_y, vl_X, vl_y = crossvalid_data\n",
    "    XXs.append(vl_X)\n",
    "    yys.append(vl_y)\n",
    "    \n",
    "    model = LogisticRegression(alpha=0.00025,max_iter=20000,C=C)\n",
    "    model.fit(tr_X, tr_y)        \n",
    "    models.append(model)\n",
    "\n",
    "f1s = []\n",
    "for thrd in thresh_vals:\n",
    "    f1_folds = []\n",
    "    \n",
    "    for ifold in range(num_fold):\n",
    "    \n",
    "        #crossvalid_data = cv[ifold]\n",
    "        #tr_X, tr_y, vl_X, vl_y = crossvalid_data\n",
    "        #model = LogisticRegression(alpha=0.001,max_iter=5000,C=C)\n",
    "        #model.fit(tr_X, tr_y)        \n",
    "        XX, yy = XXs[ifold], yys[ifold]\n",
    "        model = models[ifold]\n",
    "        preds = model.predict(XX,thrd)\n",
    "        preds = np.asarray(preds)\n",
    "        f1 = f1_score(preds,yy)\n",
    "        f1_folds.append(f1)\n",
    "    print(thrd, np.mean(f1_folds))    \n",
    "    f1s.append(np.mean(f1_folds))\n",
    "\n",
    "print(f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(f)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 28], [15, 33]]\n",
      "True positive rate 0.558824\n",
      "Precision 0.404255\n",
      "Expected Profit -0.268298\n",
      "AUC 0.549904\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Compute the expected profit of your best model for the odds\n",
    "# 1.81 vs. 1.99 and predict the outcome of the match CSKA-Rostov:\n",
    "\n",
    "# TO DO\n",
    "#import pdb; pdb.set_trace()\n",
    "test_data = np.load('CSKA-Rostov.npy')\n",
    "\n",
    "\n",
    "model = LogisticRegression(alpha=0.00025,max_iter=20000,C=C)\n",
    "model.fit(train_X, train_y)  \n",
    "preds = model.predict(test_X,0.35)\n",
    "preds = np.asarray(preds)\n",
    "cm = confusion_matrix(preds, test_y)\n",
    "print(cm)\n",
    "tpr = (cm[0][0]/np.sum(cm,axis=0)[0])\n",
    "precision = (cm[0][0]/np.sum(cm,axis=1)[0])\n",
    "print('True positive rate %f' % tpr)\n",
    "print('Precision %f' % precision)\n",
    "print('Expected Profit %f' % (precision*0.81 + (1 - precision)*-1))\n",
    "\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, preds, pos_label=None)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('AUC %f' % auc)\n",
    "\n",
    "XX = np.vstack([train_X, test_X])\n",
    "yy = np.hstack([train_y, test_y])\n",
    "model = LogisticRegression(alpha=0.00025,max_iter=20000,C=C)\n",
    "model.fit(XX, yy)  \n",
    "preds = model.predict(test_data,0.35)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 27], [15, 34]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[19, 27], [15, 34]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
