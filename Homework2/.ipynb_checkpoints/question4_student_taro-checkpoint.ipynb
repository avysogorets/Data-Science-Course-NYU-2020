{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "train_X=np.load(\"train_X.npy\")\n",
    "train_y=np.load(\"train_y.npy\")>0\n",
    "test_X=np.load(\"test_X.npy\")\n",
    "test_y=np.load(\"test_y.npy\")>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(a)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the smaller class in the training data to ensure perfect\n",
    "# class balance. Then split it into 5 folds for cross-validation.\n",
    "# You should not use sklearn.\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "pos_ratio = train_y.sum() / len(train_y)\n",
    "majority_label = 1 if pos_ratio > 0.5 else 0\n",
    "minority_label = 1 - majority_label\n",
    "# Compute the number of minority class samples we need to append\n",
    "n_samples = (train_y == majority_label).sum() - (train_y == minority_label).sum()\n",
    "minority_idxs = np.flatnonzero(train_y == minority_label)\n",
    "# Sample minority class samples with replacement\n",
    "idxs = rng.choice(minority_idxs, n_samples)\n",
    "train_X = np.concatenate((train_X, train_X[idxs]))\n",
    "train_y = np.concatenate((train_y, train_y[idxs]))\n",
    "\n",
    "# Shuffle the data, and compute 5 disjoint validation sets\n",
    "n_folds = 5\n",
    "idxs = np.arange(len(train_X))\n",
    "rng.shuffle(idxs)\n",
    "val_idxs_list = np.array_split(idxs, n_folds)\n",
    "folds = []\n",
    "for val_idxs in val_idxs_list:\n",
    "    # Use set difference to obtain the in-fold training set\n",
    "    train_idxs = np.setdiff1d(idxs, val_idxs)\n",
    "    fold_train_x, fold_train_y = train_X[train_idxs], train_y[train_idxs]\n",
    "    fold_val_x, fold_val_y = train_X[val_idxs], train_y[val_idxs]\n",
    "    folds.append((fold_train_x, fold_train_y, fold_val_x, fold_val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(b)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from Homework 1:\n",
    "# def sigmoid(t):\n",
    "#     return 1./(1+np.exp(-t))\n",
    "from scipy.special import expit as sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the L2 regularization term to the old loss function: \n",
    "def compute_loss(X, y, theta, lam):\n",
    "    return -(sum([y_i * np.log(sigmoid(np.dot(theta, X_i))) + (1 - y_i) * np.log(1 - sigmoid(np.dot(theta, X_i))) for X_i, y_i in zip(X, y)]) + lam * theta.dot(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the LogisticRegression class that supports regularization:\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, alpha, max_iter, C, tolerance=1e-5):\n",
    "        self.lam = 1 / C\n",
    "        self.alpha = alpha\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def gradient(self, X, y, theta):\n",
    "        return -(y - sigmoid(theta.dot(X.T))).dot(X) + 2 * self.lam * theta\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = y.reshape((1, X.shape[0]))\n",
    "        X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "        self.theta = np.random.normal(loc=0, scale=1, size=X.shape[1]).reshape((1, X.shape[1]))\n",
    "        progress = [0, compute_loss(X, y[0], self.theta[0], self.lam)]\n",
    "        while self.max_iter >= 0 and abs(progress[-1] - progress[-2]) > self.tolerance:\n",
    "            self.theta -= self.alpha * self.gradient(X, y, self.theta)\n",
    "            if self.max_iter % 500 == 0:\n",
    "                progress.append(compute_loss(X, y[0], self.theta[0], self.lam))\n",
    "            self.max_iter -= 1\n",
    "        return progress[1:]\n",
    "\n",
    "    def margin(self, X):\n",
    "        X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "        return np.squeeze(np.matmul(self.theta, np.transpose(X)))\n",
    "\n",
    "    def predict(self, X, thresh):\n",
    "        X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "        return [1 if sigmoid(np.dot(self.theta, X_i)) > thresh else 0 for X_i in X]\n",
    "\n",
    "    def proba(self, X):\n",
    "        X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "        return np.squeeze(np.array([sigmoid(np.dot(self.theta, X_i)) for X_i in X]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the below function. Arguments:\n",
    "# - models: K models from the K-fold cross-validation;\n",
    "# - XXs:    the corresponding validaton folds (features);\n",
    "# - yys:    the corresponding validaton folds (targets);\n",
    "# - label:  regularization constant (C);\n",
    "# - axis:   a subplot to be used for plotting;\n",
    "\n",
    "# The function should plot the ROC curve for each of the\n",
    "# models as well as their pointwise average (highlighted).\n",
    "# Moreover, plot the diagonal (0,0)-(1,1) as a dashed line\n",
    "# and print the mean AUC score.\n",
    "\n",
    "def compute_tpr_fpr(pred, y, threshold):\n",
    "    binary_pred = pred > threshold\n",
    "    n_true_pos = ((binary_pred == 1) & (y == 1)).sum()\n",
    "    n_false_pos = ((binary_pred == 1) & (y == 0)).sum()\n",
    "    n_pos = (y == 1).sum()\n",
    "    n_neg = (y == 0).sum()\n",
    "    tpr = n_true_pos / n_pos\n",
    "    fpr = n_false_pos / n_neg\n",
    "    return tpr, fpr\n",
    "\n",
    "def compute_auc(tprs, fprs):\n",
    "    sorted_idxs = np.argsort(fprs)\n",
    "    tprs_sorted = tprs[sorted_idxs]\n",
    "    fprs_sorted = fprs[sorted_idxs]\n",
    "    return np.trapz(tprs_sorted, fprs_sorted)\n",
    "\n",
    "def validate(models, XXs, yys, label, axis):\n",
    "    thresholds = np.linspace(0, 1.01, 100)\n",
    "    avg_tprs, avg_fprs = [], []\n",
    "    aucs = []\n",
    "    for fold_idx, (model, fold_val_x, fold_val_y) in enumerate(zip(models, XXs, yys)):\n",
    "        pred = model.proba(fold_val_x)\n",
    "        tprs, fprs = [], []\n",
    "        for threshold in thresholds:\n",
    "            tpr, fpr = compute_tpr_fpr(pred, fold_val_y, threshold)\n",
    "            tprs.append(tpr)\n",
    "            fprs.append(fpr)\n",
    "        axis.plot(fprs, tprs, alpha=0.75, label=f'Fold {fold_idx + 1}')\n",
    "        avg_tprs.append(tprs)\n",
    "        avg_fprs.append(fprs)\n",
    "        aucs.append(compute_auc(np.array(tprs), np.array(fprs)))\n",
    "    avg_tprs = np.array(avg_tprs)\n",
    "    avg_fprs = np.array(avg_fprs)\n",
    "    avg_tprs = avg_tprs.mean(axis=0)\n",
    "    avg_fprs = avg_fprs.mean(axis=0)\n",
    "    axis.plot(avg_fprs, avg_tprs, label='Average', color='black')\n",
    "    axis.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    axis.legend()\n",
    "    axis.set_title(label)\n",
    "    return np.mean(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(d)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your logistic regression and apply the above\n",
    "# function to each selection of C. Which is the optimal value?\n",
    "fig,axes=plt.subplots(ncols=4,nrows=2,figsize=(17,9))\n",
    "axes = axes.flatten()\n",
    "Cs=[1e-2,1e-1,1,1e1,1e2,1e3,1e4,1e5]\n",
    "\n",
    "alpha =  1e-3\n",
    "max_iter = 1e5\n",
    "\n",
    "c_to_args = {}\n",
    "for c in Cs:\n",
    "    args = {'models': [],\n",
    "            'XXs': [],\n",
    "            'yys': []}\n",
    "    for fold_idx, (fold_train_x, fold_train_y, fold_val_x, fold_val_y) in enumerate(folds):\n",
    "        model = LogisticRegression(alpha, max_iter, c)\n",
    "        model.fit(fold_train_x, fold_train_y)\n",
    "        args['models'].append(model)\n",
    "        args['XXs'].append(fold_val_x)\n",
    "        args['yys'].append(fold_val_y)\n",
    "    c_to_args[str(c)] = args\n",
    "\n",
    "aucs = []\n",
    "for ax, c in zip(axes, Cs):\n",
    "    args = c_to_args[str(c)]\n",
    "    aucs.append(validate(args['models'], args['XXs'], args['yys'], c, ax))\n",
    "\n",
    "opt_C = Cs[np.argmax(aucs)]\n",
    "print(f'C: {opt_C} is optimal with average AUC: {np.max(aucs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(e)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the below functions. The returned confusion matrix\n",
    "# should be a two-dimensional NumPy array.\n",
    "\n",
    "def confusion_matrix(predictions, labels):\n",
    "    tp = ((predictions == 1) & (labels == 1)).sum()\n",
    "    fp = ((predictions == 1) & (labels == 0)).sum()\n",
    "    tn = ((predictions == 0) & (labels == 0)).sum()\n",
    "    fn = ((predictions == 0) & (labels == 1)).sum()\n",
    "    return np.array([\n",
    "        [tp, fp],\n",
    "        [fn, tn]\n",
    "    ])\n",
    "\n",
    "def precision(predictions, labels, pos_class=1):\n",
    "    cm = confusion_matrix(predictions, labels)\n",
    "    tp = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(predictions, labels, pos_class=1):\n",
    "    cm = confusion_matrix(predictions, labels)\n",
    "    tp = cm[0, 0]\n",
    "    fn = cm[1, 0]\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(predictions, labels):\n",
    "    prec = precision(predictions, labels)\n",
    "    rec = recall(predictions, labels)\n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the appropriate threshold:\n",
    "\n",
    "thresh_vals=np.arange(0.1,0.9,0.05)\n",
    "f1_scores = []\n",
    "for thresh in thresh_vals:\n",
    "    thresh_f1_scores = []\n",
    "    for fold_idx, (fold_train_x, fold_train_y, fold_val_x, fold_val_y) in enumerate(folds):\n",
    "        model = LogisticRegression(alpha, max_iter, opt_C)\n",
    "        model.fit(fold_train_x, fold_train_y)\n",
    "        pred = model.predict(fold_val_x, thresh)\n",
    "        thresh_f1_scores.append(f1_score(np.array(pred), fold_val_y.astype(int)))\n",
    "    f1_scores.append(np.mean(thresh_f1_scores))\n",
    "opt_thresh = thresh_vals[np.argmax(f1_scores)]\n",
    "print(f'Optimal threshold: {opt_thresh:.3f}, optimal f1: {np.max(f1_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question 4(f)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the expected profit of your best model for the odds\n",
    "# 1.81 vs. 1.99 and predict the outcome of the match CSKA-Rostov:\n",
    "\n",
    "model = LogisticRegression(alpha, max_iter, opt_C)\n",
    "model.fit(train_X, train_y)\n",
    "pred_test = model.predict(test_X, opt_thresh)\n",
    "cm = confusion_matrix(np.array(pred_test), test_y)\n",
    "# Expected profit?\n",
    "pred_match = model.predict(np.load('CSKA-Rostov.npy'), opt_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = cm[0, 0]\n",
    "fp = cm[0, 1]\n",
    "precision = tp / (tp + fp)\n",
    "pnl = precision * 0.81 + (1 - precision) * -1\n",
    "print(precision, pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(test_y, pred_test))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
