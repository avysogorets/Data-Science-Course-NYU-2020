{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Introduction to Data Science, Lab 3 (9/30)\n",
    "- Statistical Learning Theory;\n",
    "- Logistic regression from scratch.\n",
    "\n",
    "## SLT: Risk and Error Decomposition\n",
    "#### Statistical Learning framework\n",
    "- *Input* space: $\\mathcal{X}$ (range of $X$), *output* space: $\\mathcal{Y}$ (range of $Y$), *action* space: $\\mathcal{A}$;\n",
    "- *Generating (data) distribution*: $(X,Y)\\sim P_{X,Y}$ over $\\mathcal{X}\\times\\mathcal{Y}$;\n",
    "- *Decision function*: $f\\colon\\mathcal{X}\\rightarrow\\mathcal{A}$ (i.e., *the model*); *hypothesis space* $\\mathcal{F}$ (an part of *inductive bias*);\n",
    "- *Evaluation function* (loss function): $\\mathcal{L}\\colon\\mathcal{A}\\times\\mathcal{Y}\\rightarrow\\mathbb{R}$ (e.g., $\\mathcal{L}(a,y)=(a-y)^2-$squared error);\n",
    "- *The statistical risk* of a decision function (expected loss): $\\mathcal{R}(f)=\\mathbb{E}_P\\mathcal{l}(f(x),y)$;\n",
    "- *Bayes decision function*: $f^{*}=\\text{argmin}_f\\mathcal{R}(f)$ (statistical risk minimizer);\n",
    "- *Risk minimizer in $\\mathcal{F}$*: $f_{\\mathcal{F}}=\\text{argmin}_{f\\in\\mathcal{F}}\\mathcal{R}(f)=\\text{argmin}_{f\\in\\mathcal{F}}\\mathbb{E}_P\\mathcal{L}(f(X),Y)$;\n",
    "- Given data $\\mathcal{D}=\\{(x_i,y_i)\\}_{i=1}^{n}$, *empirical risk*: $\\hat{\\mathcal{R}}_{\\mathcal{D}}(f)=\\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{L}(f(x_i),y_i)$;\n",
    "- *Empirical risk minimizer (ERM) in $\\mathcal{F}$*: $\\hat{f}_{\\mathcal{F},\\mathcal{D}}=\\text{argmin}_{f\\in\\mathcal{F}}\\hat{\\mathcal{R}}_{\\mathcal{D}}(f)=\\text{argmin}_{f\\in\\mathcal{F}}\\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{L}(f(x_i),y_i)$; does it always exist?\n",
    "- *Excess risk* of a function $f$: $E(f)=\\mathcal{R}(f)-\\mathcal{R}(f^{*})$ (can $\\mathcal{E}(f)$ be negative?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "Consider input/output/action spaces be $\\mathcal{X}=\\mathcal{Y}=\\mathcal{A}=\\mathbb{Z}$, generating (data) distribution $P_{X\\times Y}$ to be unifom on $\\{(-2,0),(0,0),(0,2),(2,1),(2,2)\\}$, hypothesis space $\\mathcal{F}=\\{\\alpha x+\\beta\\colon \\alpha,\\beta\\in\\mathbb{R}\\}$ of linear functions on $\\mathbb{R}$, loss function $\\mathcal{L}(a,y)=|a-y|$. What is the Bayes decision function $f^{*}$ and its risk (called *Bayes risk*) $\\mathcal{R}(f^{*})$? What $\\mathcal{F}$ will have a smaller/larger Bayes risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot([-2,2.5],[0,1.125],linestyle='-',color='grey',lw=2.5)\n",
    "#plt.plot([-2,2.5],[0,2.25],linestyle='-',color='grey',lw=2.5)\n",
    "#plt.fill_between(x=[-2,2.5],y1=[0,1.125],y2=[0,2.25],alpha=0.3,color=\"grey\")\n",
    "plt.scatter([-2,0,0,2,2],[0,0,2,1,2],c=\"fuchsia\",s=100)\n",
    "\n",
    "#[plt.plot([0,1-i*0.02],[0,2.5],linestyle='-',color='grey',lw=0.5-0.01*i) for i in range(50)]\n",
    "#plt.scatter([0,0],[0,2],c=\"turquoise\",s=100)\n",
    "\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "plt.ylim((-1,3))\n",
    "plt.xlim((-3,3))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "#### Excess Risk Decomposition\n",
    "The excess risk of an ERM minimizer in $\\mathcal{F}$ given data $\\mathcal{D}$ can be decomposed: $E(\\hat{f}_{\\mathcal{F},\\mathcal{D}})=\\mathcal{R}(\\hat{f}_{\\mathcal{\\mathcal{F},D}})-\\mathcal{R}(f^{*})=\\mathcal{R}(\\hat{f}_{\\mathcal{\\mathcal{F},D}})-\\mathcal{R}(f_{\\mathcal{F}})+\\mathcal{R}(f_{\\mathcal{F}})-\\mathcal{R}(f^{*})$.\n",
    "- *Estimation error*: $\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}=\\mathcal{R}(\\hat{f}_{\\mathcal{\\mathcal{F},D}})-\\mathcal{R}(f_{\\mathcal{F}})$ (is it always non-positive, always non-negative, or neither?);\n",
    "- *Approximation error*: $\\mathcal{E}_{\\mathcal{F}}=\\mathcal{R}(f_{\\mathcal{F}})-\\mathcal{R}(f^{*})$ (is it always non-positive, always non-negative, or neither?),\n",
    "\n",
    "so that $E(\\hat{f}_{\\mathcal{F},\\mathcal{D}})=\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}+\\mathcal{E}_{\\mathcal{F}}$. The modelling task in a nutshell: (a) Choose a loss function $\\mathcal{L}$, (b) choose a hypothesis space $\\mathcal{F}$, (c) optimize the empirical risk $\\mathcal{\\hat{R}}_{\\mathcal{D}}(f)$ over $\\mathcal{F}$. Do you always expect (or want) to get an ERM minimizer $\\hat{f}_{\\mathcal{F},\\mathcal{D}}$ as a result? Why or why not?\n",
    "\n",
    "In practice, we will get some $\\tilde{f}_{\\mathcal{F},\\mathcal{D}}$ as a result of optimization. We thus can define *optimization error* $\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}^{(o)}=\\mathcal{R}(\\tilde{f}_{\\mathcal{F},\\mathcal{D}})-\\mathcal{R}(\\hat{f}_{\\mathcal{F},\\mathcal{D}})$. Hence the excess risk of the resulting model $\\tilde{f}_{\\mathcal{F},\\mathcal{D}}$ is\n",
    "\n",
    "$$E(\\tilde{f}_{\\mathcal{F},\\mathcal{D}})=\\mathcal{R}(\\tilde{f}_{\\mathcal{F},\\mathcal{D}})-\\mathcal{R}(\\hat{f}_{\\mathcal{F},\\mathcal{D}})+\\mathcal{R}(\\hat{f}_{\\mathcal{\\mathcal{F},D}})-\\mathcal{R}(f_{\\mathcal{F}})+\\mathcal{R}(f_{\\mathcal{F}})-\\mathcal{R}(f^{*})=\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}^{(o)}+\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}+\\mathcal{E}_{\\mathcal{F}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand $\\tilde{f}_{\\mathcal{F},\\mathcal{D}}$ and optimization error $\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}^{(o)}$ better:\n",
    "1. Is optimization error $\\mathcal{E}_{\\mathcal{F},\\mathcal{D}}^{(o)}=\\mathcal{R}(\\tilde{f}_{\\mathcal{F},\\mathcal{D}})-\\mathcal{R}(\\hat{f}_{\\mathcal{F},\\mathcal{D}})$ always non-positive, always non-negative, or neither?\n",
    "2. Is quantity $\\hat{\\mathcal{R}}_{\\mathcal{D}}(\\tilde{f}_{\\mathcal{F},\\mathcal{D}})-\\hat{\\mathcal{R}}_{\\mathcal{D}}(\\hat{f}_{\\mathcal{F},\\mathcal{D}})$ always non-positive, always non-negative, or neither?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Exercises\n",
    "1. Let $\\mathcal{F}_1\\subseteq\\mathcal{F}_2$ be two hypothesis spaces. Is the difference of approximation errors $\\mathcal{E}_{\\mathcal{F}_1}-\\mathcal{E}_{\\mathcal{F}_2}$ always non-positive, always non-negative, or neither?\n",
    "2. Let $\\mathcal{F}$ be some hypothesis space and $\\mathcal{D}_1,\\mathcal{D}_2$ be two datasets generated by $P_{X\\times Y}$ with $|\\mathcal{D}_1|<|\\mathcal{D}_2|$. Is $\\mathcal{E}_{\\mathcal{F},\\mathcal{D}_1}-\\mathcal{E}_{\\mathcal{F},\\mathcal{D}_2}$ always non-positive, always non-negative, or neither? What about $\\mathcal{E}^{(o)}_{\\mathcal{F},\\mathcal{D}_1}-\\mathcal{E}^{(o)}_{\\mathcal{F},\\mathcal{D}_2}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Implementation\n",
    "From a probabilistic perspective, logistic regression is a parametric predictive model $Y\\sim Bernoulli(\\sigma(\\theta^T X))$, where $\\sigma=(1+e^{-\\theta^T X})^{-1}$ is a logistic function applied to $\\theta^T X$ where $\\theta$ is a parameter vector of the model. \n",
    "\n",
    "#### Theory of fitting\n",
    "The likelihood $\\mathcal{L}$ and negative log-likelihood $l$ functions of this model are\n",
    "\n",
    "$$\\mathcal{L}(\\theta|Y)=p(y|X,\\theta)=\\prod_{i=1}^{n}\\sigma\\left(\\theta^T \\bar{x_i}\\right)^{y_i}\\left(1-\\sigma\\left(\\theta^T\\bar{x_i}\\right)\\right)^{1-y_i},$$\n",
    "$$l(\\theta)=-\\sum_{i=1}^{n}y_i\\log\\sigma\\left(\\theta^T\\bar{x}_i\\right)+(1-y_i)\\log\\left(1-\\sigma\\left(\\theta^T \\bar{x}_i\\right)\\right),$$\n",
    "$$l(\\theta)=-\\sum_{i=1}^{n}y_i\\log\\left(1+e^{\\theta^T\\bar{x}_i}\\right)^{-1}+(1-y_i)\\log\\left(\\frac{e^{\\theta^T \\bar{x}_i}}{1+e^{\\theta^T\\bar{x}_i}}\\right),$$\n",
    "$$l(\\theta)=-\\sum_{i=1}^{n}-y_i\\log\\left(1+e^{\\theta^T\\bar{x}_i}\\right)+\\theta^T\\bar{x}_i-y_i\\theta^T\\bar{x}_i-\\log(1+e^{\\theta^T\\bar{x}_i})+y_i\\log\\left(1+e^{\\theta^T\\bar{x}_i}\\right)$$\n",
    "$$l(\\theta)=-\\sum_{i=1}^{n}\\theta^T\\bar{x}_i-y_i\\theta^T\\bar{x}_i-\\log(1+e^{\\theta^T\\bar{x}_i})$$\n",
    "\n",
    "\n",
    "The loss fuction above is called *binary cross-entropy*; it frequently appears in the classification setting. We will use gradient descent on the likelihood function to obtain an estimate $\\hat{\\theta}$. Therefore, we need to compute partial derivatives\n",
    "\n",
    "$$\\frac{\\partial l}{\\partial\\theta_j}=-\\sum_{i=1}^{n}x_{ij}-y_{i}x_{ij}-\\frac{x_{ij}e^{\\theta^T\\bar{x}_i}}{1+e^{\\theta^T\\bar{x}_i}}=-\\sum_{i=1}^{n}x_{ij}\\left(-y_{i}+\\sigma\\left(\\theta^T\\bar{x}_i\\right)\\right)=\\sum_{i=1}^{n}x_{ij}y_{i}-x_{ij}\\sigma\\left(\\theta^T\\bar{x}_i\\right)$$\n",
    "\n",
    "Now, let's fugure out the update rules. Letting $\\alpha$ be the learning rate, we have\n",
    "\n",
    "$$\\theta^{(t+1)}_j=\\theta^{(t)}_j-\\alpha\\frac{\\partial l}{\\partial\\theta_{j}}\\biggr|_{\\theta=\\theta^{(t)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory of predicting\n",
    "Given input vector $\\bar{x}$, the output of logistic regression is a number $\\sigma\\left(\\theta\n",
    "^T\\bar{x}\\right)\\in[0,1]$. To convert it into a prediction $y\\in\\{0,1\\}$, we need to agree on the mapping $\\sigma\\left(\\theta^T\\bar{x}\\right)\\mapsto y$. By default, the threshold value is naturally set to $\\tau=0.5$, i.e. $y=\\mathbb{1}_{\\sigma\\left(\\theta^T\\bar{x}\\right)\\geq 0.5}$. The choice of $\\tau$ affects the trade-off between type I/II errors; $\\tau=0.5$ is the unbiased choice, where we don't differentiate between error types. However, in some applications, costs associated with type I/II errors might be surprisingly different (can you think of such scenarios)?  Therefore, it is common to consider other [biased] threshold values. In fact, one common measure of model's performance is *AUC ROC (Area Under the Receiver Operating Curve)*, which evaluates the model at all thresholds simultaneously (more later in this course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "Disclaimer: we will write the most basic Logistic Regression class that only supports gradient descent (not stochastic), only one initialization scheme, no regularization or data randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# We will reuse the voting data from last time:\n",
    "train=pd.read_csv('clean_train.csv',sep=',',index_col=0)\n",
    "test=pd.read_csv('clean_test.csv',sep=',',index_col=0)\n",
    "train_X=train.iloc[:,:-1]\n",
    "train_y=train.iloc[:,-1].astype(int)\n",
    "test_X=test.iloc[:,:-1]\n",
    "test_y=pd.DataFrame(test.iloc[:,-1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to avoid sigmoid saturation:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "train_X=scaler.fit_transform(train_X)\n",
    "test_X=scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions:\n",
    "def sigmoid(t):\n",
    "    return 1./(1+math.e**t)\n",
    "\n",
    "def compute_loss(X,y,theta):\n",
    "    return -sum([y_i*np.log(sigmoid(np.dot(theta,X_i)))+(1-y_i)*np.log(1-sigmoid(np.dot(theta,X_i))) for X_i,y_i in zip(X,y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LogisticRegression class:\n",
    "class LogisticRegression():\n",
    "    def __init__(self,alpha,max_iter,tolerance=1e-5):\n",
    "        self.alpha=alpha\n",
    "        self.tolerance=tolerance\n",
    "        self.max_iter=max_iter\n",
    "    def gradient(self,X,y,theta):\n",
    "        return [sum([X_i[j]*y_i-X_i[j]*sigmoid(np.dot(X_i,theta)) for X_i,y_i in zip(X,y)]) for j in range(X.shape[1])]\n",
    "    def fit(self,X,y):\n",
    "        progress=[]\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        self.theta=np.random.normal(loc=0,scale=1,size=X.shape[1])\n",
    "        loss=compute_loss(X,y,self.theta)\n",
    "        while self.max_iter>0 and loss>self.tolerance:\n",
    "            if self.max_iter%50==0:\n",
    "                progress.append(loss)\n",
    "            self.theta-=self.alpha*np.array(self.gradient(X,y,self.theta))\n",
    "            loss=compute_loss(X,y,self.theta)\n",
    "            self.max_iter-=1\n",
    "        return progress\n",
    "    def predict(self,X):\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        return [1 if sigmoid(np.dot(self.theta,X_i))>0.5 else 0 for X_i in X]\n",
    "    def proba(self,X):\n",
    "        X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        return [sigmoid(np.dot(self.theta,X_i)) for X_i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model:\n",
    "iterations=10000\n",
    "model=LogisticRegression(0.01,iterations)\n",
    "progress=model.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training:\n",
    "plt.plot(range(iterations)[::50],progress,color='fuchsia',label=\"training loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss value\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch predictions:\n",
    "test_y[\"predicted\"]=model.predict(test_X)\n",
    "test_y[\"correct?\"]=(test_y[\"predicted\"]==test_y[\"trumpWinner\"]).astype(int)\n",
    "test_y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we assessed the difficulty of a particular state (observation) by calculating the variance of the associated predictions across all learners in the ensemble. Can we get similar insights from our logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual \"probabilities\" (sigmoid output):\n",
    "test_y=pd.DataFrame(test_y,dtype=object) # otherwise Pandas will convert all ints to floats;\n",
    "test_y[\"probability\"]=[round(p,2) for p in model.proba(test_X)]\n",
    "test_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to Sklearn's implementation:\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "model_2=LR(penalty='none',max_iter=iterations)\n",
    "model_2.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=test_y.drop(\"probability\",axis=1)\n",
    "test_y[\"predicted (sk)\"]=model_2.predict(test_X)\n",
    "test_y[\"correct (sk)?\"]=(test_y[\"predicted (sk)\"]==test_y[\"trumpWinner\"]).astype(int)\n",
    "test_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "direction": "ltr",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
