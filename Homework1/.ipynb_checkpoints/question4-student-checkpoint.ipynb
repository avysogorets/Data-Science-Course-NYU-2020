{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train=pd.read_csv('train_elections.csv',index_col=0)\n",
    "test=pd.read_csv('test_elections.csv',index_col=0)\n",
    "features=train.columns[:-2]\n",
    "target=\"trumpWinner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (a):\n",
    "\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz as export\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "def visualize(skl_tree):\n",
    "    dot_format=export(skl_tree,class_names=[\"Clinton\",\"Trump\"],filled=True,feature_names=features)\n",
    "    pydot_graph=pydotplus.graph_from_dot_data(dot_format)\n",
    "    pydot_graph.set_size('\"4,4!\"')\n",
    "    display(graphviz.Source(pydot_graph.to_string()))\n",
    "\n",
    "'''Fit a decision tree on your train data and visualize it'''\n",
    "\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Recreate this tree using if-else statements by completing the below function.\n",
    " - argument: a Pandas DataFrame corresponding to a single test state;\n",
    " - return: a boolean prediction for the target variable;\n",
    "'''\n",
    "\n",
    "def tree_alias(inp):\n",
    "    # TO DO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your results (run this cell):\n",
    "ifelse_preds=[tree_alias(test.loc[state]) for state in test.index]\n",
    "sklearn_preds=model.predict(test.loc[:,features])\n",
    "results=[[int(ie),int(sk),int(not ie^sk)] for ie,sk in zip(ifelse_preds,sklearn_preds)]\n",
    "results_df=pd.DataFrame(results,columns=['tree alias','tree sklearn','match?'],index=test.index)\n",
    "display(results_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fetch predictions from the fitted model (or use your 'tree_alias function')\n",
    "and compare them to ground truth on the test set. In particular, create a Pandas\n",
    "DataFrame named 'results_df' as above but with 'predicted', 'truth', 'correct?'\n",
    "as rows and test states as columns. How many are classified correctly?\n",
    "'''\n",
    "\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (b):\n",
    "\n",
    "import math\n",
    "def extended_log(arg):\n",
    "    return 0 if not arg else math.log(arg)\n",
    "def entropy(p):\n",
    "    return -sum([p_i*extended_log(p_i) for p_i in p])\n",
    "\n",
    "'''\n",
    "Complete the class 'decision stump' that has attributes/methods:\n",
    "- attribute 'self.split_feature': the name of the optimal splitting feature;\n",
    "- attribute 'self.split_value': value at which self.split_feature should be split on;\n",
    "- method 'fit(self,X,y)': decides on the above two attributes based on given Pandas\n",
    "DataFrames X and y holding features and targets for all training examples, respectively.\n",
    "Returns the list [self.split_feature,self.split_value] after fitting.\n",
    "- method 'predict(self,X)': returns a list of predictions given a Pandas DataFrame X\n",
    "holding features of some number of test examples. \n",
    "'''\n",
    "\n",
    "class decision_stump():\n",
    "    def __init__(self):\n",
    "        self.split_feature=None\n",
    "        self.split_value=None\n",
    "    def fit(self,X,y):\n",
    "        # TO DO\n",
    "        return None\n",
    "    def predict(self,X):\n",
    "        # TO DO\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compare your implementation to one from sklearn; in particular, fit a sklearn's\n",
    "decision stump on the same training data, visualize the resulting tree and compare\n",
    "to your model in terms of the splitting feature and the splitting value. Comment\n",
    "on your findings.\n",
    "'''\n",
    "\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create another table like 'results_df' for the test set with the following rows:\n",
    "(a) truth, (b) decision tree correct?, (c) decision stump correct? Does your decision\n",
    "stump perform worse than the tree you fitted before? Are mistakes the same or not?\n",
    "Comment on advantages and disadvatages of a decision stump compared to a decision tree.\n",
    "'''\n",
    "\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part (c):\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "'''\n",
    "Fit a random forest of 200 sklearn's decision stumps. Use entropy as splitting\n",
    "criterion, bootstrap sampling of the training data and consider a random subset\n",
    "of only 5 features for each split (effectively, for each tree). \n",
    "'''\n",
    "\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add the 'random forest correct?' row to the table we created in the previous part\n",
    "How does it perform compared to the decision stump? Compared to the decision tree?\n",
    "'''\n",
    "\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a Pandas Dataframe showing one sample standard deviation of predictions across\n",
    "all learners in the forest for each test state (hint: we did it in lab 2). Add the \n",
    "'random forest correct?' row to the table. Comment on your findings.\n",
    "'''\n",
    "\n",
    "# TO DO"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
