{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science, Lab 5 (10/14)\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Data profiling (manual and with ```pandas_profiling```)\n",
    "\n",
    "The material in this notebook is based on the Responsible Data Science course taught by Julia Stoyanovich in Spring 2020\n",
    "\n",
    "### *EDA and Data Profiling*\n",
    "\n",
    "Explorative Data Analysis (EDA) refers to a systematic methods of analyzing data. EDA was coined in 1961 by John Tukey in an attempt to shift emphasis from statistical hypothesis testing to selecting useful data-inspired hypotheses to test with appropriate statistical tools.\n",
    "\n",
    "Data Profiling is a subset of EDA that focuses on descriptive statistics of the dataset and assesin data quality before performing more sophisticated EDA. In this sense, data profiling can be viewed as a \"pre-processing\" stage to EDA. Some intra-column data profiling analysis includes specifying the ```length```, ```type```, ```uniqueness```, ```missingness``` of values. For numeric features, ```minimum```, ```maximum```, ```mean```, ```mode```, ```variation```, ```quantiles``` (for example, summarized in a box-plot).\n",
    "\n",
    "### *Manual Profiling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "data=pd.DataFrame(data=np.c_[iris['data'],iris['target']],columns=iris['feature_names']+['target'])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand diminsions:\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of target:\n",
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary as histogram:\n",
    "data['target'].value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of \"petal width (cm)\":\n",
    "data['petal width (cm)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Box-plot a numeric column:\n",
    "data.boxplot(column='petal width (cm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-plot multiple numeric columns:\n",
    "data.boxplot(column=['petal width (cm)','sepal length (cm)','petal length (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pandas built-in for descriptive statistics:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we have non-numeric types?\n",
    "data['text']=['lorem ipsum']*len(data)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.describe())\n",
    "data.drop(\"text\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've alredy seen these:\n",
    "display(data.head(5))\n",
    "display(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also sample some rows randomly: \n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saw this in Lab 1\n",
    "print(data.columns)\n",
    "print(data.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns:\n",
    "new_cols=[\"sepal_length\",\"sepal width\",\"petal_length\",\"petal_width\",\"class\"]\n",
    "data=data.rename(columns={col:new_col for col,new_col in zip(data.columns,new_cols)})\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas query:\n",
    "data.query('petal_length*1.1>sepal_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative method from Lab 2:\n",
    "data[1.1*data['petal_length']>data['sepal_length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll see that this hypothesis doesn’t hold. You get an empty DataFrame back as a result.\n",
    "\n",
    "Note that this function can also be expressed as iris[iris.Petal_length > iris.Sepal_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values:\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Handling missing data*\n",
    "Dealing with missing data is, of course, data- and domain-specific. However, there are two common approaches:\n",
    "- *Deletion:* sometimes missing values do not carry any significance; e.g., the dataset we downloaded from the internet had compatibility issues when saved as ```.csv``` in Excel, producing some extraneous rows with *NaNs*. Deleting rows or even columns with missing data in such cases is safe;\n",
    "- *Imputation*: missing values sometimes do carry information and discarding them might bias the analysis (can you think of examples?). In such cases, missing data is often substituted with a column mean, mode, or median. In more sophisticated analyses, a missing value can be substituted with an extraplated value (e.g., predicted with k-NN based on other features). Additionally, it is sometimes effective to add a binary feature to the data indicating which values from a particular column were missing (no information loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('property data.csv')\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that .isnull() counts only NaNs:\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('property data.csv',na_values=[\"na\",\"--\"])\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impute missing values properly, we need to understand types of variables (e.g., we cannot impute a missing value of a categorical variable with mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine types of variables:\n",
    "for col in data.columns:\n",
    "    print(f'{col}: {data.loc[:,col].apply(lambda x: type (x)).unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a feature indicating a missing value in 'SQ_FT':\n",
    "data['SQ_FT MV']=data['SQ_FT'].isnull()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imputate missing values in 'SQ_FT' with mean:\n",
    "mean=np.mean(data['SQ_FT'])\n",
    "data['SQ_FT'].fillna(mean,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas also provides linear interplotation:\n",
    "data['PID'].interpolate(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "data=pd.DataFrame(data=np.c_[iris['data'],iris['target']],columns=iris['feature_names']+['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation:\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation visualized:\n",
    "corr=data.corr()\n",
    "corr.style.background_gradient(cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Pandas Profiling Library*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas delivers a ```pandas_profiling``` library that automatically generates reports from a pandas DataFrame.\n",
    "For each column in the DataFrame, ```panas_profiling``` reports the following statistics (when applicable):\n",
    "\n",
    "- Overview (type,unique values,missing values, etc.);\n",
    "- Descriptive statistics (range, quantiles, etc.)\n",
    "- Histograms and correlation matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "data=pd.read_csv(\"Meteorite_Landings.csv\",encoding='UTF-8')\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report:\n",
    "ppf=pandas_profiling.ProfileReport(data)\n",
    "ppf.to_file(\"pandas-profiling.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Mask Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask analysis (string pattern analysis) discovers the structure of values symbol-by-symbol. Symbols ar partitioned into and encoded as\n",
    "- lower case letter: 'l';\n",
    "- capital case letter: 'L'\n",
    "- digit: 'D'\n",
    "- space: 's'\n",
    "- missing value: '-null-'\n",
    "\n",
    "Special characters (all other symbold, e.g. ?!^#@) are left uncoded. Examples of mask analysis:\n",
    "- 'Van' returns 'Lll'\n",
    "- 'VAN' returns 'LLL'\n",
    "- 'Van BC' returns 'LllsLL'\n",
    "- '+1 123-1234-5555 returns '+DsDDD-DDDD-DDDD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('2017business_licences.csv')\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask analysis:\n",
    "def getMask(field):\n",
    "    mask=''\n",
    "    if str(field)=='nan':\n",
    "        mask='-null-'\n",
    "    else:    \n",
    "        for character in str(field):\n",
    "            if 65<=ord(character)<=90: # ascii 65 to 90 are capital letters;\n",
    "                mask+='L'                \n",
    "            elif 97<=ord(character)<=122: # ascii 97 to 122 are lower case letters;\n",
    "                mask+='l'\n",
    "            elif 48<=ord(character)<=57: # ascii 48 to 57 are digits.\n",
    "                mask+='D'\n",
    "            elif ord(character)==32:\n",
    "                mask+='s'\n",
    "            else:\n",
    "                mask=mask+character\n",
    "    return mask\n",
    "\n",
    "def mask_profile(series):    \n",
    "    value=series.apply(getMask).value_counts()\n",
    "    percentage=round(series.apply(getMask).value_counts(normalize=True)*100,2)\n",
    "    result=pd.DataFrame(value)\n",
    "    result['%']=pd.DataFrame(percentage)\n",
    "    result.columns=['Count','%']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_profile(data['LicenceNumber']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_profile(data['House']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_profile(data['PostalCode']).head(5)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
